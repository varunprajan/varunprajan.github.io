<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2021-11-27T08:26:47-08:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Varun’s blog</title><subtitle>Data science + data engineering posts</subtitle><entry><title type="html">Sic transit</title><link href="http://localhost:4000/blog/sic-transit/" rel="alternate" type="text/html" title="Sic transit" /><published>2021-08-13T21:07:59-07:00</published><updated>2021-08-13T21:07:59-07:00</updated><id>http://localhost:4000/blog/sic-transit</id><content type="html" xml:base="http://localhost:4000/blog/sic-transit/">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Data changes over time: old data sources are deprecated, new data sources are added, attributes are modified, event semantics and data models are evolved, and so on. How do we avoid the maintenance &amp;quot;tax&amp;quot; associated with keeping our downstream models, dashboards, and ad-hoc queries up-to-date with these changes?&lt;/p&gt;
&lt;p&gt;The solution is obvious conceptually, even if it is not obvious how to implement it. We need to separate the form of the data from its function: how the data is represented in a database from how it is accessed. This is much like how an API (&amp;quot;application programming interface&amp;quot;) provides methods for interacting with a service that are logically separated from the computations occurring within the service itself. As a programmer, I do not care how the data for the exchange rate between US and Canadian dollars is stored, so long as I can retrieve it on a particular day. This provides the API developer the freedom to modify the data store without impacting the programmer's code. Quite similarly, we would like an interface for data access that a dashboard developer can use without needing to know about changes to data sources, data models, event semantics, etc.&lt;/p&gt;
&lt;p&gt;At this point, it is worth being somewhat more concrete, because the statements above are probably too broad and vague to be practically useful. Let's start with some definitions and distinctions.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;For the purposes of this discussion, a &amp;quot;data source&amp;quot; is a table or view that can be queried in SQL. A &amp;quot;query&amp;quot; accesses one or more data sources to generate another dataset: queries can be standalone (for ad-hoc analysis), or can be used to power dashboards, ML models, derived datasets (which constitute new data sources), etc.&lt;/li&gt;
&lt;li&gt;A query can &amp;quot;break&amp;quot; either syntactically or semantically. The former (&amp;quot;syntactic&amp;quot;) is easier to diagnose: it means that the query is gramatically incorrect, and it won't compile. This can happen if a column is removed from a data source that the query references, or if the data source itself is deprecated. More common is the latter case (&amp;quot;semantic&amp;quot;), however. This means that the query still compiles and runs, but the result is no longer correct. If I write a query that constructs a dataset for daily revenue, and the company introduces a new revenue source not captured by my query, my query remains syntactically correct but becomes broken semantically. These breakages are much more insidious because they are essentially &amp;quot;silent errors&amp;quot;.&lt;/li&gt;
&lt;li&gt;Some changes to the data model necessitate updates to queries; others don't. The difference is whether we are changing the syntax or semantics of our data model. A syntactic change is something that leaves the meaning of the data source intact but changes what various entities are called. Examples include renaming attributes, renaming data values, switching APIs (assuming they have equivalent data that is somewhat differently named), etc. Semantic changes, such as the &amp;quot;new revenue source&amp;quot; example discussed above, will always require associated work to update queries.&lt;/li&gt;
&lt;li&gt;To phrase it differently: semantic changes to the data model guarantee that queries will break semantically. However, syntactic changes to the data model can cause &lt;em&gt;either&lt;/em&gt; semantic or syntactic breakages. As an example, if we drop an attribute of an event in our application code, then our query would be broken syntactically if we also dropped the corresponding column in our data source. But, the query would be broken semantically if we did not drop the column and instead populated it with &lt;code&gt;NULL&lt;/code&gt;s when the attribute is missing.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;goals&quot;&gt;Goals&lt;/h3&gt;
&lt;p&gt;What are our goals here?&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;em&gt;Syntactic data model changes&lt;/em&gt;: We would like to grant our application developers the freedom to make syntactic changes to the data model -- to rename poorly-named event attributes and data values to better ones, etc. -- without having to do much (or any) work to keep our queries up to date. We would also like to ensure that if a data source (API, etc.) that we rely on becomes deprecated, we can seamlessly switch to a new one that is semantically equivalent, again without wasting gobs of analysts' time.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Semantic data model changes&lt;/em&gt;: We would like any changes that affect the semantics of the data model to be properly accounted for in the queries that the analytics team builds. In this case, we concede that we must make changes to our downstream queries, but the goal is to make this work as lightweight as possible.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;a-case-study&quot;&gt;A case study&lt;/h3&gt;
&lt;p&gt;Suppose we have a chess mobile app (such as &lt;a href=&quot;http://reallybadchess.com/&quot;&gt;Really Bad Chess&lt;/a&gt;, which I highly recommend). Suppose the app makes money when a player purchases lessons (on how to play chess really badly, presumably). We might imagine a transactions table that looks like this:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;center&quot;&gt;player_id&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;event_at&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;lesson_id&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;revenue_usd&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2021-08-01 02:00:01&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;Bad Chess&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;1.99&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2021-08-05 02:00:01&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;Worse Chess&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2.99&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;2&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2021-08-10 02:00:01&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;The Worst Chess&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;4.99&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We want to be able to compute how much revenue each player generates, how much each lesson makes per day, etc. These queries are straightforward to write; the latter might look like:&lt;/p&gt;
&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;event_at&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;DATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;purchase_date&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lesson_id&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SUM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;revenue_usd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;revenue_usd&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transactions&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h4 id=&quot;enter-a-problem&quot;&gt;Enter: a problem&lt;/h4&gt;
&lt;p&gt;Our mobile app developer realizes that she had implemented the transaction event incorrectly in the first version of the app (1.0.0): some of these transactions are fraudulent, and we don't actually receive money for them. She decides to implement a new event, &lt;code&gt;ValidTransaction&lt;/code&gt;, that should track only non-fraudulent transactions. So that we can get an estimate of what percentage of transactions are fraudulent, she decides to keep the existing event in place. Later, when our sample size is large enough, we will deprecate the existing event. She excitedly announces that these changes will go out in app version 1.0.1, and the existing event will eventually be deprecated in yet another app version (not yet decided on). How do we keep the query written above from breaking, both syntactically and semantically?&lt;/p&gt;
&lt;p&gt;This is surprisingly tricky. There are three periods: one in which only the existing event is firing (1.0.0 and before); one in which both events are firing (1.0.1 to some unknown version); and one in which only the new event is firing (the unknown version and after). Furthermore, these periods don't necessarily correspond to calendar dates: different users will upgrade their chess mobile app on different dates. Finally, if we add attributes for the app version or event name, both of which are currently missing, these will not be backfilled in the source table itself. See example dataset below:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;center&quot;&gt;player_id&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;event_at&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;lesson_id&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;revenue_usd&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;app_version&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;event_name&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2021-08-01 02:00:01&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;Bad Chess&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;1.99&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;NULL&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;NULL&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2021-08-05 02:00:01&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;Worse Chess&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2.99&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;NULL&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;NULL&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;2&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2021-08-10 02:00:01&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;The Worst Chess&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;4.99&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;NULL&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;NULL&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2021-08-15 02:00:01&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;The Worst Chess&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;4.99&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;1.0.1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;OldTransaction&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2021-08-15 02:00:01&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;The Worst Chess&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;4.99&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;1.0.1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;ValidTransaction&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&quot;solutions&quot;&gt;Solutions&lt;/h3&gt;
&lt;p&gt;There are a few interrelated solutions to this problem.&lt;/p&gt;
&lt;h4 id=&quot;view-layer&quot;&gt;View layer&lt;/h4&gt;
&lt;p&gt;Use a &amp;quot;view layer&amp;quot; on top of the raw table. &lt;em&gt;All&lt;/em&gt; queries, whether they are in dashboards, Jupyter notebooks, ML data preparation jobs, etc, should reference the view instead of the table itself. To repeat: no one should reference the raw data in the table. The view can encapsulate the logic for assigning defaults, renaming columns, dealing with backwards compatibility, etc. So, we might have something like (in dbt style):&lt;/p&gt;
&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- transactions_cleaned.sql&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;materialized&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'view'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;player_id&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;event_at&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lesson_id&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;revenue_usd&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;app_version&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;COALESCE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;event_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'OldPurchase'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;event_name&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'transactions'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;By creating a single point of contact with the raw, granular data, we can avoid making changes to every single downstream query when simple, syntactic changes to the data model happen, such as renaming of attributes or data values (like enums). (Of course, if we make &lt;em&gt;semantic&lt;/em&gt; changes to the data model, it is likely that many downstream queries will still need to be updated.)&lt;/p&gt;
&lt;p&gt;The view layer has an additional benefit: if we need to replace the underlying data source with a new one that is semantically equivalent, that becomes as simple as replacing &lt;code&gt;data_table_old&lt;/code&gt; with &lt;code&gt;data_table_new&lt;/code&gt; in the view layer, and none of the downstream queries need to know the difference.&lt;/p&gt;
&lt;h4 id=&quot;analytics-versioning&quot;&gt;Analytics versioning&lt;/h4&gt;
&lt;p&gt;Unfortunately, we are still not able to compute the revenue by lesson easily. We need to be able to apply different business logic depending on which of the three periods described above the event pertains to. So, something like:&lt;/p&gt;
&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;event_at&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;DATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;purchase_date&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lesson_id&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SUM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;CASE&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;WHEN&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;period_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'OldPurchase'&lt;/span&gt;
                &lt;span class=&quot;c1&quot;&gt;-- note: this is only approximate, because of the error&lt;/span&gt;
                &lt;span class=&quot;c1&quot;&gt;-- we might try applying a discount factor to the revenue,&lt;/span&gt;
                &lt;span class=&quot;c1&quot;&gt;-- based on the comparison of OldPurchase and ValidPurchase in period 2&lt;/span&gt;
                &lt;span class=&quot;c1&quot;&gt;-- in order to fix this&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;THEN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;revenue_usd&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;WHEN&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;period_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'ValidPurchase'&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;THEN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;revenue_usd&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;WHEN&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;period_3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'ValidPurchase'&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;THEN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;revenue_usd&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;ELSE&lt;/span&gt;
                &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;END&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;revenue_usd&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transactions_cleaned&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The periods are not defined by &lt;code&gt;event_at::DATE&lt;/code&gt;, for the reasons described above. Instead, they correspond to the version of the app that was released, the &lt;code&gt;app_version&lt;/code&gt;. Unfortunately, semantic versions are difficult to compare in SQL. More generically, it is useful to create a separate attribute, which I will call the &lt;code&gt;analytics_version&lt;/code&gt;, that tracks changes to the data model and can be used for cases like these in which having consistent logic for historical and current events is important. The &lt;code&gt;analytics_version&lt;/code&gt; can be attached to every event, and &lt;a href=&quot;https://calver.org/&quot;&gt;calendar versioning&lt;/a&gt; can be used to make the SQL easier to write. So, we might have something like:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;center&quot;&gt;player_id&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;event_at&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;lesson_id&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;revenue_usd&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;app_version&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;event_name&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;analytics_version&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2021-08-01 02:00:01&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;Bad Chess&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;1.99&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;NULL&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;NULL&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;NULL&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2021-08-05 02:00:01&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;Worse Chess&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2.99&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;NULL&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;NULL&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;NULL&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;2&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2021-08-10 02:00:01&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;The Worst Chess&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;4.99&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;NULL&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;NULL&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;NULL&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2021-08-15 02:00:01&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;The Worst Chess&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;4.99&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;1.0.1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;OldPurchase&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2021.08.10&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2021-08-15 02:00:01&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;The Worst Chess&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;4.99&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;1.0.1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;ValidPurchase&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2021.08.10&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;where, each time the analytics in the application code undergoes a semantic change, the &lt;code&gt;analytics_version&lt;/code&gt; is bumped to the date of the release. With this, we can write our view layer as:&lt;/p&gt;
&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- transactions_cleaned.sql&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;materialized&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'view'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;player_id&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;event_at&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lesson_id&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;revenue_usd&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;app_version&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;COALESCE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;event_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'OldPurchase'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;event_name&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;-- some arbitrarily old date&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;COALESCE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;analytics_version&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'1970.01.01'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;analytics_version&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'transactions'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;and our desired query as:&lt;/p&gt;
&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;event_at&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;DATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;purchase_date&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lesson_id&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SUM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;CASE&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;WHEN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;analytics_version&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'2021.08.10'&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;event_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'OldTransaction'&lt;/span&gt;
                &lt;span class=&quot;c1&quot;&gt;-- again, this is only approximate&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;THEN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;revenue_usd&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;WHEN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;analytics_version&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'2021.08.10'&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;event_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'ValidTransaction'&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;THEN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;revenue_usd&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;ELSE&lt;/span&gt;
                &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;END&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;revenue_usd&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transactions_cleaned&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h4 id=&quot;metrics-layer&quot;&gt;Metrics layer&lt;/h4&gt;
&lt;p&gt;There is still a problem: any time that we want to write a new query that involves the revenue, we need to copy this complicated &amp;quot;CASE/WHEN&amp;quot; logic into that query. Each different type of aggregation -- whether by player, lesson, date, or combinations thereof -- will require this logic. Thus, although we've solved the problem of computing the revenue, we've set ourselves up for a potential maintenance headache. Our code is the opposite of &lt;a href=&quot;https://en.wikipedia.org/wiki/Don%27t_repeat_yourself&quot;&gt;DRY&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;There are a few ways to address this issue, although none of them seems particularly good to me.&lt;/p&gt;
&lt;p&gt;(This problem was also discussed by Benn Stancil and his solution is a &lt;a href=&quot;https://benn.substack.com/p/metrics-layer&quot;&gt;&amp;quot;metrics layer&amp;quot;&lt;/a&gt;, which seems theoretically correct to me although I have yet to see a practical implementation. Others refer to this problem as &lt;a href=&quot;https://basecase.vc/blog/headless-bi&quot;&gt;&amp;quot;Headless BI&amp;quot;&lt;/a&gt;)&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;We can rewrite the &lt;code&gt;revenue_usd&lt;/code&gt; column in the view, like so:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;materialized&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'view'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;player_id&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;event_at&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lesson_id&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;CASE&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;WHEN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;COALESCE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;analytics_version&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'1970.01.01'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'2021.08.10'&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;COALESCE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;event_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'OldTransaction'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'OldTransaction'&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;-- note: this is only approximate, because of the error&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;-- we might try applying a discount factor to the revenue,&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;-- based on the comparison of OldPurchase and ValidPurchase in period 2&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;-- in order to fix this&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;THEN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;revenue_usd&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;WHEN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;analytics_version&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'2021.08.10'&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;event_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'ValidTransaction'&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;THEN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;revenue_usd&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;ELSE&lt;/span&gt;
            &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;END&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;revenue_usd&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;app_version&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;COALESCE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;event_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'OldTransaction'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;event_name&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;-- some arbitrarily old date&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;COALESCE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;analytics_version&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'1970.01.01'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;analytics_version&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'transactions'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This strikes me as being wrong aesthetically, although I'm not able to fully articulate why. Moreover, it does not allow us to run the analysis comparing the revenue from the old and new events during period 2: the revenue from the former will be zeroed out.&lt;/p&gt;
&lt;ol start=&quot;2&quot;&gt;
&lt;li&gt;
&lt;p&gt;We can encode this definition into LookML. This works as far as Looker goes, but it is not accessible outside of the Looker environment.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We can have the logic exist in &lt;code&gt;dbt&lt;/code&gt;. This works only if queries need only access the aggregated/transformed data created by &lt;code&gt;dbt&lt;/code&gt;. In my experience, this is not always the case.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We can accept that the logic will not be centralized, and manually update our queries when a change to the revenue definition is made. This becomes easier if the queries are source controlled and easily deployable. This is not the case for most BI tools (Tableau, etc.), and, as the list of places that queries live becomes more expansive -- Jupyter notebooks/&lt;a href=&quot;https://airbnb.io/projects/knowledge-repo/&quot;&gt;knowledge repositories&lt;/a&gt;, BI tools, data apps, ML models, dbt, etc. -- this solution becomes increasingly untenable. To take one example, suppose we conduct an analysis in a Jupyter notebook and deploy it to a knowledge repository to make it available to the entire company. What happens if the data model changes and the queries residing within the notebook break semantically? How do we ensure that our findings remain reproducible?&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;summary-and-conclusions&quot;&gt;Summary and conclusions&lt;/h3&gt;
&lt;p&gt;To conclude:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Keeping queries synchronized with changes to the data model can be an onerous task. Analysts tasked with stuff they don't enjoy doing (query maintenance) instead of stuff they do (deriving data insights) are also likelier to leave.&lt;/li&gt;
&lt;li&gt;The goal of an analytics team should be to make syntactic changes to the data model trivial to implement, and semantic changes relatively easy. Unless this is the case, old code, outdated attribute names and events, and undesirable ways of instrumenting the application will linger, creating &amp;quot;analytics debt&amp;quot; that will only build up with time.&lt;/li&gt;
&lt;li&gt;We do not yet have the tools to solve this problem completely, or even well. The fundamental problem is that for semantic changes to the data model, like our new transaction event, there is no single place (a &amp;quot;metrics layer&amp;quot;) to encode the logic for a metric/aggregation that is easily accessible by all downstream queries.&lt;/li&gt;
&lt;li&gt;That being said, using a view layer to encapsulate
the raw source data is one good approach for making updates related to syntactic changes much less work to implement.&lt;/li&gt;
&lt;li&gt;As our case study revealed, dealing with event data can be tricky because of backwards compatibility issues. Incorporating an &lt;code&gt;analytics_version&lt;/code&gt; can make it possible to compute historical metrics that otherwise would not be.&lt;/li&gt;
&lt;li&gt;Making analytics conform more to practices from software engineering (source control, one-button deployment) can ameliorate the issues described above partly, but not wholly. Many of the leading BI tools, such as Tableau, do a poor job of this. This partly reflects the historical divisions between engineering and analytics: divisions that I feel are somewhat artificial.&lt;/li&gt;
&lt;/ol&gt;</content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html">Introduction</summary></entry><entry><title type="html">A random walk down Wall Street</title><link href="http://localhost:4000/blog/a-random-walk-down-wall-street/" rel="alternate" type="text/html" title="A random walk down Wall Street" /><published>2021-08-13T21:07:59-07:00</published><updated>2021-08-13T21:07:59-07:00</updated><id>http://localhost:4000/blog/a-random-walk-down-wall-street</id><content type="html" xml:base="http://localhost:4000/blog/a-random-walk-down-wall-street/">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;I was lucky enough to receive an offer from a tech company recently, and, as part of that offer, a substantial equity package. This company allows you to choose your own mix of equity. On your first day, you can choose to allocate your equity across four categories: cash, restricted stock units (RSUs), and two types of options, one aggressive (&amp;quot;at the money&amp;quot;, or ATM) and the other very aggressive (&amp;quot;out of the money&amp;quot;, OTM). The value of the equity package (for the non-cash options) depends on how the stock price evolves during one's tenure. If the stock price increases greatly, the OTM and ATM options are superior to RSUs, which in turn is superior to cash. If the stock price drops, the ranking is reversed. While the HR department provided a helpful guide to understand the mechanics of each option, and informed me that, if I couldn't make a decision, I would be opted-in to a mix of 75% RSUs and 25% ATM options, I wanted to understand the value of this package in greater detail. (The term &amp;quot;value&amp;quot; is ill-defined, and I'll return to it later.)&lt;/p&gt;
&lt;p&gt;I decided to tackle this problem using simulation. Simulation is a very powerful approach because it allows you to analyze mathematical problems where closed-form, analytical solutions do not exist. In this case, as long as I can describe the evolution of the stock price from time $t$ to time $t+1$, then I can slowly step through time and determine the stock price N steps out. (If my equity vests over 4 years, and each step is a month, I would want to repeat the process of going from $t$ to $t+1$ 48 times.) In doing so, I have simulated one scenario of the future, and, with some extra work, I can determine the value of my equity package, given a particular allocation, within that scenario. I can repeat the exercise many times to generate a plethora of such scenarios. Finally, I can repeat that set of steps with a different allocation to determine how this collection of futures would change depending on my decision of how to allocate my equity. I would somehow then have to aggregate these scenarios and compare them across allocations in order to reach a final decision about which allocation to choose. Presumably, I would want to choose the allocation that maximized the &amp;quot;value&amp;quot; I referred to previously. To put a mathematical gloss on it:&lt;/p&gt;
&lt;h2 id=&quot;goals&quot;&gt;Goals&lt;/h2&gt;
&lt;p&gt;What are our goals here?&lt;/p&gt;
&lt;h4 id=&quot;enter-a-problem&quot;&gt;Enter: a problem&lt;/h4&gt;
&lt;h3 id=&quot;solutions&quot;&gt;Solutions&lt;/h3&gt;
&lt;h2 id=&quot;summary-and-conclusions&quot;&gt;Summary and conclusions&lt;/h2&gt;
&lt;p&gt;To conclude:&lt;/p&gt;</content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html">Introduction I was lucky enough to receive an offer from a tech company recently, and, as part of that offer, a substantial equity package. This company allows you to choose your own mix of equity. On your first day, you can choose to allocate your equity across four categories: cash, restricted stock units (RSUs), and two types of options, one aggressive (&amp;quot;at the money&amp;quot;, or ATM) and the other very aggressive (&amp;quot;out of the money&amp;quot;, OTM). The value of the equity package (for the non-cash options) depends on how the stock price evolves during one's tenure. If the stock price increases greatly, the OTM and ATM options are superior to RSUs, which in turn is superior to cash. If the stock price drops, the ranking is reversed. While the HR department provided a helpful guide to understand the mechanics of each option, and informed me that, if I couldn't make a decision, I would be opted-in to a mix of 75% RSUs and 25% ATM options, I wanted to understand the value of this package in greater detail. (The term &amp;quot;value&amp;quot; is ill-defined, and I'll return to it later.) I decided to tackle this problem using simulation. Simulation is a very powerful approach because it allows you to analyze mathematical problems where closed-form, analytical solutions do not exist. In this case, as long as I can describe the evolution of the stock price from time $t$ to time $t+1$, then I can slowly step through time and determine the stock price N steps out. (If my equity vests over 4 years, and each step is a month, I would want to repeat the process of going from $t$ to $t+1$ 48 times.) In doing so, I have simulated one scenario of the future, and, with some extra work, I can determine the value of my equity package, given a particular allocation, within that scenario. I can repeat the exercise many times to generate a plethora of such scenarios. Finally, I can repeat that set of steps with a different allocation to determine how this collection of futures would change depending on my decision of how to allocate my equity. I would somehow then have to aggregate these scenarios and compare them across allocations in order to reach a final decision about which allocation to choose. Presumably, I would want to choose the allocation that maximized the &amp;quot;value&amp;quot; I referred to previously. To put a mathematical gloss on it: Goals What are our goals here? Enter: a problem Solutions Summary and conclusions To conclude:</summary></entry><entry><title type="html">Adventures in incremental dbt</title><link href="http://localhost:4000/blog/adventures-in-incremental-dbt/" rel="alternate" type="text/html" title="Adventures in incremental dbt" /><published>2020-12-24T20:07:59-08:00</published><updated>2020-12-24T20:07:59-08:00</updated><id>http://localhost:4000/blog/adventures-in-incremental-dbt</id><content type="html" xml:base="http://localhost:4000/blog/adventures-in-incremental-dbt/">&lt;p&gt;(For those of you who don't know what &lt;code&gt;dbt&lt;/code&gt; is or how it works, parts of this post might be confusing. I'd recommend starting with the documentation and working through an example to get your feet wet. That being said, if you know SQL and a little bit of Jinja, most of what I write below should make sense.)&lt;/p&gt;
&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;I love &lt;code&gt;dbt&lt;/code&gt;. It is a tool for &amp;quot;ELT&amp;quot;, as opposed to &amp;quot;ETL&amp;quot;: in other words, transforming the &amp;quot;source&amp;quot; data in your data lake/data warehouse after it has been loaded, as opposed to before.&lt;/p&gt;
&lt;p&gt;(The reasons you might want to adopt the ELT paradigm are too involved to explain in this post, but one main one is that transforming the source data &lt;em&gt;before&lt;/em&gt; it arrives in your data warehouse is often irreversible and therefore inflexible. By contrast, transforming the raw data &lt;em&gt;after&lt;/em&gt; is reversible: if you decide that a different data model is appropriate, you can simply wipe away the previously generated &amp;quot;transformed data&amp;quot; and start anew from the source data.)&lt;/p&gt;
&lt;p&gt;A &lt;a href=&quot;https://blog.getdbt.com/future-of-the-modern-data-stack/&quot;&gt;few different trends&lt;/a&gt; have driven the rapid adoption of &lt;code&gt;dbt&lt;/code&gt;. First, the relative cheapness of storage means that storing source data in a raw, unaggregated form is economical. Second, the rise of data warehouses such as Redshift and Snowflake means that this SQL &amp;quot;transformation layer&amp;quot; is both easy to write and performant on large datasets. Redshift and Snowflake support distributed/parallel SQL in a way that traditional &amp;quot;OLTP&amp;quot; databases, such as Postgres, do not.&lt;/p&gt;
&lt;p&gt;Typically, &lt;code&gt;dbt&lt;/code&gt; is run as a nightly cron job: each night, it will execute a set of SQL queries against the raw source data and produce the &amp;quot;derived&amp;quot; or &amp;quot;transformed&amp;quot; data, which are the tables that support your analysts, dashboards, and possibly even ML applications. This process might strike you as inefficient, particularly for source data that comprises (stateless) events. If only the source data loaded in the last 24 hours has changed between the prior &lt;code&gt;dbt&lt;/code&gt; run and the current one, why not simply process that data instead of reprocessing the entire table?&lt;/p&gt;
&lt;p&gt;For this purpose, &lt;code&gt;dbt&lt;/code&gt; supplies the concept of &amp;quot;incremental&amp;quot; materialization: instead of reprocessing the entire source table, we can process the &lt;em&gt;increment&lt;/em&gt; of new data. In this post, I will use a case study to demonstrate how this works and some problems I've run into.&lt;/p&gt;
&lt;h2 id=&quot;a-case-study&quot;&gt;A case study&lt;/h2&gt;
&lt;p&gt;Suppose we have a table called &lt;code&gt;user_transactions&lt;/code&gt;. It captures the revenue for each transaction (say, buying an item on our e-commerce store) associated with a user. It might look like this:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;center&quot;&gt;user_id&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;birth_date&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;date&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;revenue&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-01&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-01&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-01&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-01&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-01&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-03&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;6.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-01&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-07&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;14.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-01&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-08&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;5.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;2&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-02&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-05&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;6.00&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Here, the &lt;code&gt;user_id&lt;/code&gt; is the unique identifier for the user; the &lt;code&gt;date&lt;/code&gt; is the date of activity (the date the transaction occurred); the &lt;code&gt;birth_date&lt;/code&gt; is the date the user joined our service (was &amp;quot;born&amp;quot;), and the &lt;code&gt;revenue&lt;/code&gt; is the dollar amount collected. We can, of course, have multiple transactions for a user on a particular date.&lt;/p&gt;
&lt;p&gt;(One subtle point: Note that this representation is denormalized, since the &lt;code&gt;user_id&lt;/code&gt; + &lt;code&gt;birth_date&lt;/code&gt; relationship is fixed, and could/should be a separate table. In other words, we could have a separate &lt;code&gt;users&lt;/code&gt; table, of which the &lt;code&gt;birth_date&lt;/code&gt; is a dimension. The &lt;code&gt;users&lt;/code&gt; table would be a &amp;quot;dimension&amp;quot; table, &lt;a href=&quot;https://stackoverflow.com/questions/20036905/difference-between-fact-table-and-dimension-table&quot;&gt;in the language&lt;/a&gt; of data modeling, and the original &lt;code&gt;user_transactions&lt;/code&gt; table would become a &amp;quot;fact&amp;quot; table. In what follows, however, I've chosen to keep this denormalized representation because it makes writing the subsequent SQL easier.)&lt;/p&gt;
&lt;p&gt;Our goal in this case study is to compute the cumulative revenue per user for various time windows: specifically, 3, 7, 60, and 365 days after the user joined our service. We refer to the cumulative revenue up to day N as the &amp;quot;DN revenue&amp;quot;. For the example data above, user 1's D1 revenue is $20.00; D2 revenue is $30.00, and D4 revenue is $81.00. In contrast, user 3's D1 and D2 revenue is $0.00 (they did not spend in the their first 2 days), but their D4 revenue is $30.00.&lt;/p&gt;
&lt;p&gt;(Another subtle point: some numbering conventions use 0-based indexing, so that our &amp;quot;D1 revenue&amp;quot; would be equivalent to their &amp;quot;D0 revenue&amp;quot;. Be attentive to this &amp;quot;off-by-one&amp;quot; issue when writing your own business logic.)&lt;/p&gt;
&lt;h3 id=&quot;attempt-1-full-table-refresh&quot;&gt;Attempt 1: full table refresh&lt;/h3&gt;
&lt;p&gt;The simplest approach is to create a derived table (say, &lt;code&gt;user_cumulative_revenue&lt;/code&gt;), and to refresh the entire table each day. The SQL would look like this:&lt;/p&gt;
&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;user_id&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;birth_date&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SUM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;CASE&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;WHEN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DATEDIFF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;DAY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;birth_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;THEN&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;revenue&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;ELSE&lt;/span&gt;
            &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;END&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d3_revenue&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SUM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;CASE&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;WHEN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DATEDIFF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;DAY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;birth_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;THEN&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;revenue&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;ELSE&lt;/span&gt;
            &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;END&lt;/span&gt;
     &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d7_revenue&lt;/span&gt;
     &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ref&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'user_transactions'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;(where &lt;code&gt;ref&lt;/code&gt; is &lt;code&gt;dbt&lt;/code&gt;'s way of referring to other tables/data sources. Note that &lt;a href=&quot;https://docs.getdbt.com/docs/building-a-dbt-project/using-sources/&quot;&gt;source&lt;/a&gt; might be even better than &lt;code&gt;ref&lt;/code&gt; here.)&lt;/p&gt;
&lt;p&gt;Using &lt;code&gt;dbt&lt;/code&gt;'s jinja functionality, we can clean up the repetitive logic like so:&lt;/p&gt;
&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- attempt_1.sql&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_windows&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;365&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;user_id&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;birth_date&lt;/span&gt;
    &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_window&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_windows&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SUM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;CASE&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;WHEN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DATEDIFF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;DAY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;birth_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_window&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;THEN&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;revenue&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;ELSE&lt;/span&gt;
            &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;END&lt;/span&gt;
     &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_window&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_revenue&lt;/span&gt;
     &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;endfor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ref&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'user_transactions'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;There's still one error in our logic, however. For day windows that are &amp;quot;incomplete&amp;quot; — for instance, if a user has been with us for only 2 days but we want to find their D3 revenue — we should make the result &lt;code&gt;NULL&lt;/code&gt;. We want to calculate the D3 revenue only when the 3 day window for a particular user is complete. We can incorporate that logic like so:&lt;/p&gt;
&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- attempt_1_fixed.sql&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_windows&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;365&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;user_id&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;birth_date&lt;/span&gt;
    &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_window&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_windows&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,(&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;CASE&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;WHEN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DATEDIFF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;DAY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;birth_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CURRENT_DATE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_window&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;THEN&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;SUM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;CASE&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;WHEN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DATEDIFF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;DAY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;birth_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_window&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;THEN&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;revenue&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;ELSE&lt;/span&gt;
                    &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;END&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;ELSE&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;NULL&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;END&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_window&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_revenue&lt;/span&gt;
    &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;endfor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ref&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'user_transactions'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;(Lots of nesting! This could be simplified if your database supports the &lt;code&gt;IFF&lt;/code&gt; and/or &lt;code&gt;NULLIF&lt;/code&gt; keywords.)&lt;/p&gt;
&lt;p&gt;In other words, we set the DN revenue to be &lt;code&gt;NULL&lt;/code&gt; if insufficient time has elapsed between the user's &lt;code&gt;birth_date&lt;/code&gt; and the current date.&lt;/p&gt;
&lt;p&gt;(One more subtle note: I'm assuming that the last &lt;em&gt;complete&lt;/em&gt; day of data is &lt;code&gt;CURRENT_DATE - 1&lt;/code&gt; . This is true if the &lt;code&gt;dbt&lt;/code&gt; job runs somewhat after midnight UTC and our data is loaded in a timely way. In practice, this assumption might be dangerous, however, and data &lt;a href=&quot;https://docs.getdbt.com/reference/commands/source#dbt-source-snapshot-freshness&quot;&gt;&amp;quot;freshness&amp;quot;&lt;/a&gt; checks are probably needed.)&lt;/p&gt;
&lt;h3 id=&quot;attempt-2-incremental-naive&quot;&gt;Attempt 2: incremental, naive&lt;/h3&gt;
&lt;p&gt;The approach developed above &amp;quot;works&amp;quot;, but you might notice that it's rather inefficient. First of all, even though our maximum LTV window is 365 days, our query scans over the  entire &lt;code&gt;user_transactions&lt;/code&gt; table, even for users who joined more than 365 days ago, and for transactions that occurred more than 365 days ago. If we were to filter out these users and transactions, however, then the data for them would not appear in the final table, which is bad. What we need is a way to update the data for the last 365 days without destroying the data from dates before that. &lt;code&gt;dbt&lt;/code&gt;'s default approach is to destroy the previous table and create a new one, which isn't appropriate in this case.&lt;/p&gt;
&lt;p&gt;Enter the &lt;code&gt;dbt&lt;/code&gt; incremental materialization. Here, we have to define a key or set of keys for &amp;quot;upserting&amp;quot; new data. If the keys for the new rows match those for existing rows in the table, the existing rows are overwritten. If the keys do not match, the new rows are inserted. This might seem confusing, but the basic idea, as applied to this case study, is that our transformed data has a unique id: we have one row per user. We only want to update rows for which the user's &lt;code&gt;birth_date&lt;/code&gt; is in the last 365 days; for older users, their data need not be recomputed, since it is fixed and should not change.&lt;/p&gt;
&lt;p&gt;The SQL looks something like this:&lt;/p&gt;
&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- attempt_2.sql&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;materialized&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'incremental'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;unique_key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'user_id'&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;

&lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_windows&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;365&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;user_id&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;birth_date&lt;/span&gt;
    &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_window&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_windows&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,(&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;CASE&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;WHEN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DATEDIFF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;DAY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;birth_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CURRENT_DATE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_window&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;THEN&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;SUM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;CASE&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;WHEN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DATEDIFF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;DAY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;birth_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_window&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;THEN&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;revenue&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;ELSE&lt;/span&gt;
                    &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;END&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;ELSE&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;NULL&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;END&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_window&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_revenue&lt;/span&gt;
    &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;endfor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ref&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'user_transactions'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;is_incremental&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;DATEDIFF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;DAY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;birth_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CURRENT_DATE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_windows&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;max&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;-- superfluous, but might help query optimizer&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DATEDIFF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;DAY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CURRENT_DATE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_windows&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;max&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;endif&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Pretty simple, right? The only things that have changed are the configuration of the &lt;code&gt;dbt&lt;/code&gt; model and the date filters (in the &lt;code&gt;WHERE&lt;/code&gt; clause). We can run this in &lt;code&gt;full-refresh&lt;/code&gt; mode initially, which will create the entire table from scratch by ignoring the &lt;code&gt;is_incremental&lt;/code&gt; WHERE clause; then, on all subsequent runs, we can run this model in incremental mode, which will respect the &lt;code&gt;is_incremental&lt;/code&gt; &lt;code&gt;WHERE&lt;/code&gt; clause and avoid reprocessing data for old users. For more details on how this works, here is the &lt;a href=&quot;https://docs.getdbt.com/docs/building-a-dbt-project/building-models/configuring-incremental-models/&quot;&gt;dbt documentation&lt;/a&gt; for incremental models.&lt;/p&gt;
&lt;p&gt;(As an aside, this incremental query will be more efficient only if the source data is sorted/indexed appropriately. In Redshift, we would need to have a &lt;a href=&quot;https://www.flydata.com/blog/amazon-redshift-distkey-and-sortkey/&quot;&gt;sort/dist key&lt;/a&gt; that involves either the &lt;code&gt;date&lt;/code&gt; and/or the &lt;code&gt;birth_date&lt;/code&gt;. In Snowflake, these keys/indexes are managed for you, and it is likely that this optimization would take place. If we had separated the source data into dimension and fact tables, the choice of keys would be somewhat different.)&lt;/p&gt;
&lt;h3 id=&quot;attempt-3-incremental-more-sophisticated&quot;&gt;Attempt 3: incremental, more sophisticated&lt;/h3&gt;
&lt;p&gt;It turns out that even this incremental model is rather inefficient, in the sense of scanning over rows that don't matter. How inefficient? Well, each day we have only 4 &lt;code&gt;birth_date&lt;/code&gt; &amp;quot;cohorts&amp;quot; that mature. As an example, let's suppose we are processing data on Jan 1, 2020, and the last date of data available is for Dec 31, 2019. There are four important milestones that have been reached:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The cohort with &lt;code&gt;birth_date&lt;/code&gt; Dec 29, 2019 has completed 3 days of activity, so its D3 revenue can be computed.&lt;/li&gt;
&lt;li&gt;The cohort with &lt;code&gt;birth_date&lt;/code&gt; Dec 25, 2019 has completed 7 days of activity, so its D7 revenue can be computed.&lt;/li&gt;
&lt;li&gt;The cohort with &lt;code&gt;birth_date&lt;/code&gt; Nov 2, 2019 has completed 60 days of activity, so its D60 revenue can be computed.&lt;/li&gt;
&lt;li&gt;The cohort with &lt;code&gt;birth_date&lt;/code&gt; Jan 1, 2019 has completed 365 days of activity, so its D365 revenue can be computed.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Importantly, no other cohorts have matured or hit an important milestone! In other words, if we reprocess the last 365 days of &lt;code&gt;birth_date&lt;/code&gt;s, we will be scanning over 365/4 = 91 times as many rows as is necessary. (Whether this means the query will take 91 times as long is a separate question; it is unlikely that the performance degradation would be that severe.)&lt;/p&gt;
&lt;p&gt;You might argue that modern distributed SQL is fast enough that this doesn't matter. This is probably true for many applications. But, depending on our business model and number of users, the &lt;code&gt;transactions&lt;/code&gt; table might have millions or tens of millions of rows per day, and reprocessing 365 days of it might be too inefficient.&lt;/p&gt;
&lt;p&gt;Regardless, even merely as an intellectual exercise I think it is interesting to see whether we can make this logic more performant, working within the strictures of &lt;code&gt;dbt&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Let's try to directly implement this idea related to cohort maturation. On a given date, we will reprocess only the four &lt;code&gt;birth_date&lt;/code&gt; cohorts that have matured. My attempt looks like this:&lt;/p&gt;
&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- attempt_3.sql&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;materialized&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'incremental'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;unique_key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'user_id'&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;

&lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_windows&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;365&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;user_id&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;birth_date&lt;/span&gt;
    &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_window&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_windows&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,(&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;CASE&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;WHEN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DATEDIFF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;DAY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;birth_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CURRENT_DATE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_window&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;THEN&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;SUM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;CASE&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;WHEN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DATEDIFF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;DAY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;birth_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_window&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;THEN&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;revenue&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;ELSE&lt;/span&gt;
                    &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;END&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;ELSE&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;NULL&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;END&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_window&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_revenue&lt;/span&gt;
    &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;endfor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ref&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'user_transactions'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;is_incremental&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;DATEDIFF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;DAY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CURRENT_DATE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_windows&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;max&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_window&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_windows&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;DATEDIFF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;DAY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;birth_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CURRENT_DATE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_window&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;
        &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;last&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt;
        &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;endif&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;endfor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;endif&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;which is starting to get more complicated! We have to modify the &lt;code&gt;WHERE&lt;/code&gt; clause to filter using equality statements, chained with OR, for the &lt;code&gt;birth_date&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&quot;unpivoting&quot;&gt;Unpivoting&lt;/h2&gt;
&lt;p&gt;One source of inflexibility with our current approach, which you might have noticed, is that adding new &amp;quot;day windows&amp;quot; is inefficient: we have to run a full table refresh for any new columns. In other words, if we want to compute a new, D1 cumulative revenue, the incremental materialization doesn't help us.&lt;/p&gt;
&lt;p&gt;One way to surmount this difficulty is to &lt;a href=&quot;https://github.com/fishtown-analytics/dbt-utils#unpivot-source&quot;&gt;&amp;quot;unpivot&amp;quot;&lt;/a&gt; the table: for each user, we will have N rows, one for each day window of interest. Then, when we need to add a new day window, all we need to do is insert a new row for each user, and this operation does not require a full table refresh. This might be a bit tough to visualize, so here is what the old table looked like:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;center&quot;&gt;user_id&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;birth_date&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;d3_revenue&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;d7_revenue&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;d60_revenue&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;d365_revenue&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-01&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;10.00&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;24.00&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;NULL&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;NULL&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;2&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-02&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;0.00&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;6.00&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;NULL&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;NULL&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;and this is what the new, pivoted table looks like:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;center&quot;&gt;user_id&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;birth_date&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;day_window&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;revenue&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-01&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;3&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;10.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-01&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;7&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;24.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;2&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-02&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;3&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;0.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;2&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-02&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;7&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;6.00&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The unique key for upsertion, in this case, is the combination of the &lt;code&gt;user_id&lt;/code&gt; and the &lt;code&gt;day_window&lt;/code&gt;. How might this model be represented in &lt;code&gt;dbt&lt;/code&gt;? It's not too different from our previous model:&lt;/p&gt;
&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- attempt_pivot_incremental.sql&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;materialization&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'incremental'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;unique_key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'user_day_window_id'&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;

&lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_windows&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;365&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;WITH&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;user_id&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;birth_date&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DATEDIFF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;DAY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;birth_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CURRENT_DATE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_window&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SUM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;revenue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cumulative_revenue&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ref&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'user_transactions'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;-- select birth_dates that correspond to cohort maturation on CURRENT_DATE - 1&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_window&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_windows&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;DATEDIFF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;DAY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;birth_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CURRENT_DATE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_window&lt;/span&gt;
        &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;last&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt;
        &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;endif&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;endfor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;-- superfluous, but might help query optimizer&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;date&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;birth_date&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DATEDIFF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;DAY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CURRENT_DATE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;day_windows&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dbt_utils&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;surrogate_key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'user_id'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'day_window'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;user_day_window_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;When we turn to the &amp;quot;full table&amp;quot; model, things get complicated, though. It is not obvious how to implement this model (without using the &lt;code&gt;unpivot&lt;/code&gt; macro), which means that we cannot easily have the incremental and full models in the same model file, which &lt;code&gt;dbt&lt;/code&gt; requires. (If you have ideas, let me know!)&lt;/p&gt;
&lt;p&gt;(My best guess is that the solution involves some complicated SQL/Jinja to generate all possible combinations of (&lt;code&gt;day_window&lt;/code&gt;, &lt;code&gt;birth_date&lt;/code&gt;) tuples, and then joining that to the &lt;code&gt;user_transactions&lt;/code&gt; table. In addition to being complicated, this might also be inefficient.)&lt;/p&gt;
&lt;h2 id=&quot;taking-a-step-back&quot;&gt;Taking a step back&lt;/h2&gt;
&lt;p&gt;Even if there is a solution to this issue, I think the difficulties we had constructing it point to some deficiencies with dbt:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Writing incremental models involves reasoning carefully about the differences between the full and incremental models, and trying to include both sets of logic in a single model. This often requires SQL/Jinja gymnastics, if it is indeed possible at all.&lt;/li&gt;
&lt;li&gt;We often don't even need the full table model. We could, instead, compose the table of interest by iterating over individual incremental runs. &lt;code&gt;dbt&lt;/code&gt; does not easily support this functionality, though. &amp;quot;For&amp;quot; loops must be written within model files; they cannot be used to iterate over &lt;code&gt;dbt&lt;/code&gt; runs.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Let me try to expand upon point 2. One relatively straightforward approach would be to run the dbt model for a single tuple of (&lt;code&gt;day_window&lt;/code&gt;, &lt;code&gt;date_of_interest&lt;/code&gt;). How might this look? (I'm using the &lt;a href=&quot;https://docs.getdbt.com/docs/building-a-dbt-project/building-models/using-variables/&quot;&gt;vars syntax&lt;/a&gt; to pass these variables into the model.)&lt;/p&gt;
&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- attempt_single_tuple_incremental.sql&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;materialization&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'incremental'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;unique_key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'user_day_window_id'&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;WITH&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;user_id&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;birth_date&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;&quot;day_window&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_window&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SUM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;revenue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cumulative_revenue&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ref&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'user_transactions'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;DATEDIFF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;DAY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;birth_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'{{ var(&quot;date_of_interest&quot;) }}'&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;&quot;day_window&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;date&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'{{ var(&quot;date_of_interest&quot;) }}'&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dbt_utils&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;surrogate_key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'user_id'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'day_window'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;user_day_window_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;There's actually hardly any Jinja in this solution at all! On a particular date of interest (which we had taken to be synonymous with the current date, but could really be any date at all), we can get the desired &lt;code&gt;birth_date&lt;/code&gt; cohort by subtracting the &lt;code&gt;day_window&lt;/code&gt; from that date. For instance, for a date of interest of Jan 1, 2020, and a &lt;code&gt;day_window&lt;/code&gt; of 365, the &lt;code&gt;birth_date&lt;/code&gt; is Jan 1, 2019. Then, we simply grab all the transactions that occurred before the date of interest, for users with that birth date. Each &lt;code&gt;dbt&lt;/code&gt; run would be very fast to execute, particularly for short day windows, but there would be a &lt;em&gt;lot&lt;/em&gt; of runs: N_dates * N_day_windows.&lt;/p&gt;
&lt;p&gt;Note further that, in theory, all of these runs could be executed concurrently. Because each of them generates a separate set of rows (since each deals with a distinct &lt;code&gt;user_day_window_id&lt;/code&gt;), none of the runs should, again in theory, interfere with one another. This could make the &amp;quot;backfill&amp;quot; (the initial run to build the table from scratch from historical data) rather fast to execute.&lt;/p&gt;
&lt;p&gt;This approach is very similar to the &amp;quot;functional&amp;quot; approach to transformations, discussed &lt;a href=&quot;https://medium.com/@maximebeauchemin/functional-data-engineering-a-modern-paradigm-for-batch-data-processing-2327ec32c42a&quot;&gt;here&lt;/a&gt;. Each dbt run would process a chunk of data and generate a disjoint &amp;quot;partition&amp;quot;, indexed by the &lt;code&gt;user_day_window_id&lt;/code&gt;. The final table can be thought of as the UNION ALL of each of these different &lt;code&gt;user_day_window&lt;/code&gt; partitions.&lt;/p&gt;
&lt;p&gt;Another benefit of this approach is supporting &amp;quot;late arriving&amp;quot; events: in this context, these are transactions for which the data is received one or more days late, or cases where a transaction is refunded, so we have an additional, negative transaction that arrives one or more days later. We can incorporate these late arriving events into our logic by also running the &lt;code&gt;dbt&lt;/code&gt; job for a previous date of interest (say, 7 days ago, by which time we can assume all of the late arriving events have &amp;quot;settled&amp;quot;). This would ensure that we have approximate results immediately, and correct results with a 7 day lag. Again, the normal job and the late arriving job could conceivably run concurrently.&lt;/p&gt;
&lt;p&gt;In practice, on the other hand, implementing this solution is not at all easy:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Multiple &lt;code&gt;dbt&lt;/code&gt; jobs can be run concurrently, but it is not safe to do so. In particular, the names of intermediate VIEWs might clash, which would lead to race conditions and other bad outcomes.&lt;/li&gt;
&lt;li&gt;Databases like Redshift struggle with concurrent writes because of serializability guarantees. Telling the compiler that the partitions being generated are indeed disjoint is not easy.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dbt&lt;/code&gt; does not natively support looping over runs/tasks and supplying &amp;quot;logical dates&amp;quot; in the way that a workflow management tool like &lt;a href=&quot;https://airflow.apache.org/&quot;&gt;Airflow&lt;/a&gt; does. &lt;code&gt;dbt&lt;/code&gt; has to be combined with a tool like Airflow to get this functionality. We need the logical date to support things like backfills, retries, table rebuilds using incremental logic alone, and late arriving events. (We can use Airflow's &lt;code&gt;ds&lt;/code&gt; as dbt's &lt;code&gt;var(&amp;quot;date_of_interest&amp;quot;)&lt;/code&gt;.)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;(Others have encountered related issues: &lt;a href=&quot;https://shopify.engineering/build-production-grade-workflow-sql-modelling&quot;&gt;Shopify mentioned&lt;/a&gt; that &amp;quot;dbt’s current incremental support doesn’t provide safe and consistent methods to handle late arriving data, key resolution, and rebuilds. For this reason, a handful of models (Type 2 dimensions or models in the 1.5B+ event territory) that required incremental semantics weren’t doable—for now.&amp;quot;)&lt;/p&gt;
&lt;p&gt;It would be nice to see &lt;code&gt;dbt&lt;/code&gt; try to support this more functional approach to writing transformations. I imagine it will be difficult given the issues I've mentioned, particularly on the database side, but I'm curious to see what their team of very smart engineers can cook up!&lt;/p&gt;
&lt;p&gt;(The Github code for this project is available &lt;a href=&quot;https://github.com/varunprajan/data-eng-blog/tree/main/incremental-dbt&quot;&gt;here&lt;/a&gt;, if you're interested. The &lt;code&gt;user_transactions&lt;/code&gt; table can be generated using &lt;code&gt;dbt seed&lt;/code&gt;.)&lt;/p&gt;</content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html">(For those of you who don't know what dbt is or how it works, parts of this post might be confusing. I'd recommend starting with the documentation and working through an example to get your feet wet. That being said, if you know SQL and a little bit of Jinja, most of what I write below should make sense.)</summary></entry><entry><title type="html">Retry-driven development</title><link href="http://localhost:4000/blog/retry-driven-development/" rel="alternate" type="text/html" title="Retry-driven development" /><published>2020-12-20T20:07:59-08:00</published><updated>2020-12-20T20:07:59-08:00</updated><id>http://localhost:4000/blog/retry-driven-development</id><content type="html" xml:base="http://localhost:4000/blog/retry-driven-development/">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;I usually advise against writing your own ETL jobs. Commercial products such as Stitch and Fivetran integrate with hundreds of data sources and dozens of data destinations; they make ETL maintainable and easy. But, whether for reasons of cost or functionality, you might be forced to write your own ETL. How do you do that in a way that avoids its common pitfalls? (To &lt;a href=&quot;https://medium.com/@maximebeauchemin/functional-data-engineering-a-modern-paradigm-for-batch-data-processing-2327ec32c42a&quot;&gt;quote&lt;/a&gt; Maxime Beauchemin, creator of Apache Superset and Apache Airflow: &amp;quot;Batch data processing — historically known as ETL — is extremely challenging. It’s time-consuming, brittle, and often unrewarding. Not only that, it’s hard to operate, evolve, and troubleshoot.&amp;quot;)&lt;/p&gt;
&lt;p&gt;Data engineers should obviously borrow best practices from other disciplines of software engineering: writing clear documentation, developing robust unit and integration tests, soliciting PR reviews, etc. One under-appreciated method that has special relevance to data/analytics engineering is what I'll call &amp;quot;retry-driven development&amp;quot;. In short, &lt;em&gt;write your code in such a way that it can be retried safely and correctly&lt;/em&gt;. In other words, accept that bugs can happen that will not be covered by your test suite, but be able to recover from them effectively.&lt;/p&gt;
&lt;p&gt;To be clear, I am not claiming credit for this idea. In fact, much of this post is inspired by Beauchemin's excellent &lt;a href=&quot;https://medium.com/@maximebeauchemin/functional-data-engineering-a-modern-paradigm-for-batch-data-processing-2327ec32c42a&quot;&gt;essay&lt;/a&gt; &amp;quot;Functional Data Engineering: A Modern Paradigm for Batch Data Processing&amp;quot; (and he himself acknowledges that mature companies have been employing these ideas for years, perhaps without formalizing them in the way he has). My hope is instead to work through a concrete case study that might help illuminate some of the slightly abstract concepts he discussed.&lt;/p&gt;
&lt;h2 id=&quot;a-case-study&quot;&gt;A case study&lt;/h2&gt;
&lt;p&gt;Suppose we work for a retail company that has historically operated only in the United States, but now seeks to expand its operations worldwide. We can imagine an &lt;code&gt;order_items&lt;/code&gt; table that used to look like this:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;center&quot;&gt;order_item_id&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;order_id&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;item_name&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;amount_usd&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;ordered_at&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;Breezy Dress&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;53.49&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-01 02:00:01&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;2&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;V-neck Shirt&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;18.99&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-03 04:00:01&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;3&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;Muscle Tank&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;42.69&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-03 04:00:01&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;But will be migrated to look like this (note the additional item in a non-USD currency):&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;center&quot;&gt;order_item_id&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;order_id&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;item_name&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;amount&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;currency_code&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;ordered_at&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;Breezy Dress&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;53.49&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;USD&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-01 02:00:01&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;2&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;V-neck Shirt&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;18.99&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;USD&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-03 04:00:01&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;3&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;Muscle Tank&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;42.69&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;USD&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-03 04:00:01&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;4&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;3&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;Red Sari&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;1800.00&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;INR&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-05 23:49:04&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We would like to be able to continue reporting our daily gross revenue (in USD) in our company &amp;quot;key metrics email&amp;quot;. To do this, we will collect data on a daily basis for worldwide exchange rates in terms of USD. Suppose this table is called &lt;code&gt;historical_exchange_rates&lt;/code&gt;, with three columns, &lt;code&gt;date&lt;/code&gt; ,&lt;code&gt;currency_code&lt;/code&gt;, and &lt;code&gt;exchange_rate_usd&lt;/code&gt;, like so:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;center&quot;&gt;date&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;currency_code&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;exchange_rate_usd&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-01&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;USD&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;1.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-01&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;INR&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;0.0136&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-02&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;USD&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;1.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;...&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;...&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;...&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;our revenue query for the report would be:&lt;/p&gt;
&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ordered_at&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;DATE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;-- ignore revenue for which a matching code/date cannot be found&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SUM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;amount&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;COALESCE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exchange_rate_usd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;order_items&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LEFT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;historical_exchange_rates&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rates&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ordered_at&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;DATE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;date&lt;/span&gt;
                                             &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;currency_code&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;currency_code&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;-- only report on data from the last 60 days&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ordered_at&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CURRENT_DATE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;INTERVAL&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'60 DAY'&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;which is actually fairly straightforward. (Whether this is good enough for financial reporting is a separate issue that is out of scope for this post.)&lt;/p&gt;
&lt;h2 id=&quot;etl-first-attempt&quot;&gt;ETL, first attempt&lt;/h2&gt;
&lt;p&gt;Our first attempt at an ETL script for this &lt;code&gt;historical_exchange_rates&lt;/code&gt; table might look something like the Python code below. For brevity, I've omitted many of the details, but these should be obvious to fill in.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;logging&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;logger&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logging&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getLogger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__name__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;BASE_CURRENCY&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;USD&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;DB_CONN&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RedshiftConnection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(...)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;EMAIL_RECIPIENTS&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;alex@retailstartup.com&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;varun@retailstartup.com&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;EXCHANGE_RATES_URL&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;https://openexchangerates.org/api/&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;TABLE_NAME&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;historical_exchange_rates&quot;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;retrieve_exchange_rates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base_currency&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;transform_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;raw_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;append_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db_conn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'DatabaseConnection'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# retrieve raw data for today by making a request to the API
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;json_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;retrieve_exchange_rates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;base_currency&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BASE_CURRENCY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EXCHANGE_RATES_URL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# transform data into pandas dataframe
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;frame&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transform_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;raw_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;json_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# insert (append) it into our data warehouse table
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;append_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db_conn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DB_CONN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;table&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TABLE_NAME&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# email recipients that job finished
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;email_notification&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;recipients&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EMAIL_RECIPIENTS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;contents&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Exchange rate job succeeded!&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__name__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;__main__&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;except&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Exception&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;logger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;info&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;f&quot;Something bad happened, exception info: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;email_notification&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;recipients&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EMAIL_RECIPIENTS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;contents&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Exchange rate job failed; check logs&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;There are a lot of things to like here (at least I hope so; I'm the one who wrote it!). The code seems fairly modular, and it has function names that make sense. It also uses type hints, which can be enforced &lt;a href=&quot;http://mypy-lang.org/&quot;&gt;using &lt;code&gt;mypy&lt;/code&gt;&lt;/a&gt;. Suppose further that it has a test suite with full coverage that mocks out the API and database; the tests run via Jenkins; the code is deployed with a one-button deployment; and the job itself runs on a cron at UTC midnight but can be retried with a one-button click if needed. I would wager that this code quality and deployment process is better than many custom-built ETL pipelines at small/medium-sized companies.&lt;/p&gt;
&lt;p&gt;Yet it is also the case that this ETL pipeline does not work well. The issues stem from violating the principle of retry-driven development: if something fails, the code cannot be retried safely and/or correctly. There are a few reasons:&lt;/p&gt;
&lt;h2 id=&quot;lack-of-separation-of-environments&quot;&gt;Lack of separation of environments&lt;/h2&gt;
&lt;p&gt;Suppose something in the ETL job breaks (as it inevitably will). We would like to tinker with and run the code locally in order to debug the issue. Is this safe to do? Actually, no. Unless we have a way to mock out the (Redshift) data warehouse locally, we risk writing to our production table. And, if the Redshift connection were mocked locally, we would not be able to test that the &lt;code&gt;append_data&lt;/code&gt; function works properly. (Note that, since our test suite uses mocks, it also does not truly test the functionality of this method). What we need is a way to run a job locally that does not touch production data, but still touches Redshift.&lt;/p&gt;
&lt;p&gt;One easy way to support this workflow is to create a development schema (let's say, &lt;code&gt;varun_dev&lt;/code&gt;). (As an aside, &lt;code&gt;dbt&lt;/code&gt; enforces &lt;a href=&quot;https://docs.getdbt.com/docs/building-a-dbt-project/building-models/using-custom-schemas#managing-environments&quot;&gt;this same workflow&lt;/a&gt;). Then, we can use a Python package (I prefer &lt;a href=&quot;https://www.dynaconf.com/&quot;&gt;&lt;code&gt;dynaconf&lt;/code&gt;&lt;/a&gt;, but there are others) that sets a configuration variable differently if the code is run in the &amp;quot;development&amp;quot; environment vs. the &amp;quot;production&amp;quot; one. The code would look something like this:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;dynaconf&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;settings&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# this will be, say, &quot;raw&quot; in production but &quot;varun_dev&quot; in development
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SCHEMA_NAME&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;settings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;HISTORICAL_EXCHANGE_RATES&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SCHEMA_NAME&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# insert (append) it into our data warehouse table
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;append_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db_conn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DB_CONN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;table&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TABLE_NAME&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;schema&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SCHEMA_NAME&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;A further advantage of this approach is that multiple developers can work on the same code without interfering with each other: each will have their own development schema.&lt;/p&gt;
&lt;h2 id=&quot;issues-with-append&quot;&gt;Issues with append&lt;/h2&gt;
&lt;p&gt;Another problem with the current code has to do with the &amp;quot;append_data&amp;quot; function. Suppose the implementation uses Redshift's &lt;code&gt;COPY&lt;/code&gt; &lt;a href=&quot;https://docs.aws.amazon.com/redshift/latest/dg/r_COPY.html&quot;&gt;command&lt;/a&gt;: we write our &lt;code&gt;pandas&lt;/code&gt; dataframe to a temporary csv on S3, and then use &lt;code&gt;COPY&lt;/code&gt; to load the data from that csv into our table, by appending it to the existing data.&lt;/p&gt;
&lt;p&gt;If we retry our code, there is an issue: we don't know whether this will correct the previous failure, or if it will instead append the data &lt;em&gt;yet again&lt;/em&gt; to the table. In other words, we could have two copies of the data for a particular day, or just one.&lt;/p&gt;
&lt;p&gt;If, say, Alex leaves the company (☹️), and his email address is disabled, then our &lt;code&gt;email_notification&lt;/code&gt; function might error out, but the data in Redshift will have been loaded correctly. If, on the other hand, the failure occurs because the API was down, then the data in Redshift has not already been loaded. This behavior means we cannot safely retry the ETL job.&lt;/p&gt;
&lt;p&gt;At this point, you might ask: why can't we simply check whether the data was loaded? If it was, we don't have to retry the script; if it wasn't, we can retry the script. I would argue very strongly against this idea. Each of these manual checks adds a &amp;quot;tax&amp;quot; to the process of maintaining an ETL job. Perhaps this tax is bearable with a small number of ETL pipelines, but, as the data volume grows and the ETL complexity grows correspondingly, it will erode an analytics engineer's productive time. It would be nice if, having fixed the issue at 2 am, in advance of the morning's company metrics email, I could simply push the button to run the script and go to bed. If we feel that &amp;quot;one button&amp;quot; development processes, like CI and CD, are valuable, then &amp;quot;one button&amp;quot; ETL runs are valuable for the same reason.&lt;/p&gt;
&lt;p&gt;There are at least two ways to fix the issue with &amp;quot;append&amp;quot; I diagnosed above. One is to avoid using append; the other is to modularize our tasks in the same way that we modularized our code. Let's go one-by-one.&lt;/p&gt;
&lt;h3 id=&quot;upsert-dont-append&quot;&gt;Upsert, don't append&lt;/h3&gt;
&lt;p&gt;Upsertion is a process of updating a table wherein rows that &amp;quot;match&amp;quot; are UPdated, whereas rows that don't &amp;quot;match&amp;quot; are inSERTed (hence the name, &amp;quot;UPSERTion&amp;quot;). What does &amp;quot;match&amp;quot; mean in this context? We typically define a set of &amp;quot;primary keys&amp;quot; — the combination of these primary keys defines a unique id for the row/record. If we attempt to upsert a new row where the set of primary keys match another row already in the table, then that old row is replaced with the new one. If there is no match, a new row is inserted.&lt;/p&gt;
&lt;p&gt;(As an aside, the &lt;a href=&quot;https://docs.getdbt.com/docs/building-a-dbt-project/building-models/configuring-incremental-models/#how-do-incremental-models-work-behind-the-scenes&quot;&gt;details&lt;/a&gt; of how this is implemented vary from database to database. One simple strategy is to delete records for which the keys match, and then insert the entire dataset afterwards. Some databases, like Snowflake, support upsertion &lt;a href=&quot;https://docs.snowflake.com/en/sql-reference/sql/merge.html&quot;&gt;more natively&lt;/a&gt; though.)&lt;/p&gt;
&lt;p&gt;How can we use upsertion to our advantage in this case? By inspecting our &lt;code&gt;historical_exchange_rates&lt;/code&gt; table, we see that the combination of &lt;code&gt;date&lt;/code&gt; and &lt;code&gt;currency_code&lt;/code&gt; define a unique id. Each day we should have exactly one row per currency code. Let's take these two columns to be our primary keys. Suppose we retry the job on the same day. (The &amp;quot;on the same day&amp;quot; is an important caveat, and relaxing this restriction will be covered below.) Then, there are two possibilities:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Our previous job failed before the Redshift load step, in which case no data with &lt;code&gt;date = CURRENT_DATE&lt;/code&gt; exist, so the upsertion process will find no matches. Therefore, the entire dataset resulting from the retry job will be inserted. In this case, that's what we want.&lt;/li&gt;
&lt;li&gt;Our previous job failed after the Redshift load step, in which case data already exists with &lt;code&gt;date = CURRENT_DATE&lt;/code&gt;. The upsertion process will find matches for all of those rows and replace each of them. Arguably this is wasteful (we're replacing old data with identical new data), but it is both safe and correct.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Therefore, replacing our &amp;quot;append&amp;quot; operation with an &amp;quot;upsert&amp;quot; one makes our job safe to retry, with the caveat mentioned before.&lt;/p&gt;
&lt;p&gt;Note that upsertion is a more expensive process than appending: it involves deletes as well as inserts. It can &lt;a href=&quot;https://dataintensive.net/&quot;&gt;also&lt;/a&gt; violate certain database &amp;quot;serializability&amp;quot; guarantees if run concurrently with other processes that hit the same table. Therefore, it may not be appropriate for all cases. Furthermore, for (stateless) events, even the choice of primary keys is not obvious. Pipelines for event-based data typically have to be built with much more care to avoid dropping or duplicating events: i.e., to ensure &amp;quot;exactly once&amp;quot; delivery.&lt;/p&gt;
&lt;h3 id=&quot;modularize-the-tasks&quot;&gt;Modularize the tasks&lt;/h3&gt;
&lt;p&gt;A different approach is to &amp;quot;modularize&amp;quot; our tasks, not just our code. What does this mean? We generally write our code to maximize reusability and obey the single responsibility principle: that each function should do only one thing. Here, one function extracts the data (&lt;code&gt;retrieve_exchange_rates&lt;/code&gt;), another transforms it (&lt;code&gt;transform_data&lt;/code&gt;), another loads it into the data warehouse (&lt;code&gt;append_data&lt;/code&gt; or &lt;code&gt;upsert_data&lt;/code&gt;), and yet another sends the email (&lt;code&gt;email_notification&lt;/code&gt;). However, we have not written our tasks the same way. There is a single script that is executed via cron: it does all of the things listed above in sequence. Because different behavior occurs depending on exactly where this task fails, the retry logic becomes confusing.&lt;/p&gt;
&lt;p&gt;As an alternative, we can break up this single task into two or more tasks. For example:&lt;/p&gt;
&lt;p&gt;Task 1: &lt;code&gt;retrieve_exchange_rates&lt;/code&gt; → &lt;code&gt;transform_data&lt;/code&gt; → &lt;code&gt;upsert_data&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Task 2: &lt;code&gt;email_notification&lt;/code&gt; (depending on status of task 1)&lt;/p&gt;
&lt;p&gt;Why is this better? If task 1 completes successfully, and the data is loaded into the data warehouse, there is no need to retry it. We can instead just fix the email bug and (optionally) retry that task. On the other hand, if task 1 does not complete successfully, we can retry the whole thing (task 1 + task 2) from the beginning.&lt;/p&gt;
&lt;p&gt;You might notice that this is significantly more complicated than a simple cron job. We would like to chain together tasks in some order, store (statefully) the results of the tasks, and retry either from the beginning or partway through. What we are really after is a &amp;quot;workflow management&amp;quot; tool, of which &lt;a href=&quot;https://airflow.apache.org/&quot;&gt;Apache Airflow&lt;/a&gt; is the best-known. The core concept of such a tool is the &amp;quot;DAG&amp;quot;: a graph that describes the tasks and the dependencies between them. (In this case, task 2 depends on task 1, but not the other way around.) If you are interested in learning more, this is the &lt;a href=&quot;https://medium.com/airbnb-engineering/airflow-a-workflow-management-platform-46318b977fd8&quot;&gt;original post&lt;/a&gt; (by the same Maxime Beauchemin!) that announced the open-sourcing of Airflow and shared its design principles.&lt;/p&gt;
&lt;p&gt;You might also ask: why don't we modularize the tasks even further? If our ETL job does four separate things, why don't we have four separate tasks? This is possible and even desirable, but tricky. Remember that, according to our principle, each task needs to be able to be retried safely and correctly. How would we retry the &lt;code&gt;transform_data&lt;/code&gt; task unless we saved the results of the extraction task (&lt;code&gt;retrieve_exchange_rates&lt;/code&gt;) somewhere? Airflow does not natively support this behavior. There are two possibilities. One is to use a tool like &lt;a href=&quot;https://medium.com/the-prefect-blog/why-not-airflow-4cfa423299c4&quot;&gt;Prefect&lt;/a&gt;, which tries to improve upon Airflow by, among other things, supporting the passing of data between tasks (N.B.: I have not used Prefect). The other is to implement data passing using (cloud) storage, such as S3. In other words, we would have tasks like this:&lt;/p&gt;
&lt;p&gt;Task 1: retrieve exchange rates from API, write raw data to S3&lt;/p&gt;
&lt;p&gt;Task 2: read raw data from S3, transform, write transformed data to S3&lt;/p&gt;
&lt;p&gt;Task 3: load transformed data into db from S3&lt;/p&gt;
&lt;p&gt;Task 4: email notification&lt;/p&gt;
&lt;p&gt;Although this makes the code significantly more complicated, using S3 as an intermediate data store is actually a powerful paradigm that has non-obvious advantages, as we will see shortly.&lt;/p&gt;
&lt;p&gt;One final note on this topic: in production, I would recommend using both approaches: task modularization and upserting instead of appending. They do not interfere with one another and might even be seen as complementary.&lt;/p&gt;
&lt;h2 id=&quot;dealing-with-time&quot;&gt;Dealing with time&lt;/h2&gt;
&lt;p&gt;The final problem with our script is that it does not deal with time properly. I hope to clarify this (pseudo-profound) statement with some examples.&lt;/p&gt;
&lt;p&gt;Suppose that we are not able to retry the script on the same day. What happens, even accounting for the improvements made previously (environment separation, upserting instead of appending, and modularizing our tasks)? Unfortunately, we're screwed. If we retry the script on a different day, then it will collect data for that day and populate the &lt;code&gt;historical_exchange_rates&lt;/code&gt; table with it. But this does not solve the problem of the missing data from the day of interest. In other words, the retry is safe, but not correct.&lt;/p&gt;
&lt;p&gt;(Careful readers might notice that even retrying the script on the same day can lead to subtle issues. If the data underlying the exchange rate API changes every hour, then retrying the script in the morning will not produce exactly the same exchange rate data as if it had run successfully at midnight UTC.)&lt;/p&gt;
&lt;p&gt;We can make a final set of improvements to our script. The obvious one is to use the &lt;em&gt;historical&lt;/em&gt; exchange rates API endpoint instead of the current one. This seems easy but in fact it is incompatible with the original cron scheduler. The issue has to do with the &amp;quot;logical date&amp;quot; vs the actual date. If we retry the Dec 1 job on Dec 3, we want the date passed to the API endpoint to be Dec 1, &lt;em&gt;not&lt;/em&gt; Dec 3. In other words, each daily run of the ETL job has a &amp;quot;logical date&amp;quot; associated with it, and, even when retrying later, that logical date needs to be attached to that run. Using the actual date in place of the logical date leads to errors. While cron does not handle this issue, both Airflow and Prefect do.&lt;/p&gt;
&lt;p&gt;For many data sources, historical data is not readily available. The example of exchange rates that forms the basis of the case study might therefore be considered too optimistic. Supporting historical data lookups adds extra work (and possibly also blows up the size of the database backing the API), and many APIs choose not to support it (or, at the very least, limit the amount of time that you can look back). How do we deal with time in these cases?&lt;/p&gt;
&lt;p&gt;The solution is actually one we've already mentioned: modularizing the tasks! The key idea here is that, if we save the raw data first, then &amp;quot;downstream&amp;quot; tasks (tasks that occur after saving the raw data) can be retried both safely and correctly. Of course, if that first task fails, we're still borked, but at least errors in other parts of the code are not critical.&lt;/p&gt;
&lt;p&gt;A final concept related to &amp;quot;dealing with time&amp;quot; is &amp;quot;schema evolution&amp;quot;. It often happens that ETL jobs expand in scope. Our original exchange rate ETL job captured exchange rates in the base currency of USD. Suppose we want to be able to capture other base currencies as well. We can imagine evolving the schema by renaming the &lt;code&gt;exchange_rate_usd&lt;/code&gt; column to &lt;code&gt;exchange_rate&lt;/code&gt;, and adding a &lt;code&gt;base_currency_code&lt;/code&gt; column, backfilled to be &amp;quot;USD&amp;quot; for all existing data.&lt;/p&gt;
&lt;p&gt;While the migration of the table is straightforward, the changes for the ETL job might not be. One final application of the retry-driven development principle is that we want &lt;em&gt;historical&lt;/em&gt; retries, even of successful tasks, to be safe and correct. This gives us some peace of mind: even if the &lt;code&gt;historical_exchange_rates&lt;/code&gt; table gets dropped, for whatever reason, we can rebuild it. This requires writing the &amp;quot;transform&amp;quot; task in a careful way. We could have something like:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;transform_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;raw_data_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_raw_data_from_s3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;original&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transformation&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;code&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;exchange_rate&quot;&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;frame&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;exchange_rate_usd&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;exchange_rate&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;base_currency_code&quot;&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;base_currency_code&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;USD&quot;&lt;/span&gt;

    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;write_transformed_data_to_s3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;As you can see, this code handles the historical and current datasets properly, albeit at the cost of added complexity and extra test cases. If we did not modify it, historical retries could not be run safely or correctly. (There are better ways to handle schema evolution, and products like AWS Glue and Databricks that make this process much easier, but this code snippet was provided simply for the purpose of illustration.)&lt;/p&gt;
&lt;h2 id=&quot;summary-and-conclusions&quot;&gt;Summary and conclusions&lt;/h2&gt;
&lt;p&gt;What I like about this case study is that it is (deceptively) simple, yet it reveals many core concepts to data engineering and even data science. In my view, the principal conclusions are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Be compassionate towards your future self. Your ETL code will undoubtedly break. Write your code so that it can be retried afterwards (i.e., after fixing it) both safely and correctly.&lt;/li&gt;
&lt;li&gt;Retry-driven development has secondary benefits. An important one is that it forces you to break larger tasks down into smaller ones, in the same way that test-driven development forces you to write smaller, more testable functions. The result is &amp;quot;data flows&amp;quot; that are easier to reason about, not only because they are smaller but also because they can be safely retried without much thought.&lt;/li&gt;
&lt;li&gt;Use environments to avoid touching production data. This is probably obvious to those with an engineering background, but perhaps not to some data scientists or &amp;quot;hackers&amp;quot; who are &lt;a href=&quot;https://multithreaded.stitchfix.com/blog/2016/03/16/engineers-shouldnt-write-etl/&quot;&gt;often recruited&lt;/a&gt; to write ETL.&lt;/li&gt;
&lt;li&gt;External data is often ephemeral. If it is not too costly, saving the raw data to a data store is a good way to be able to reconstruct the data of interest at a later date.&lt;/li&gt;
&lt;li&gt;Thinking about time is surprisingly tricky! Try to walk through the possible retry scenarios (rerunning historical tasks, retrying failed tasks on the same day, and on a different day, etc.) before you write code, not after. Distinguishing between the logical data and actual date will help you reason about these cases.&lt;/li&gt;
&lt;li&gt;At some point, cron won't be good enough. Proper workflow management tools add immeasurable value by making recovering from failure straightforward and efficient (only failed tasks need to be retried, not the entire job).&lt;/li&gt;
&lt;li&gt;Upsertion is powerful way to write safe and correct data flows. It ensures that you never duplicate data, which is possible with append-based flows. Much more could be said about this topic, but I'd recommend reading the post by Maxime Beauchemin linked at the top to learn more about &amp;quot;functional data engineering&amp;quot; and &amp;quot;idemptotent&amp;quot; processes (of which upsertion is one).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Let me know your thoughts!&lt;/p&gt;</content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html">Introduction</summary></entry></feed>