<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-12-24T16:02:36-05:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Varun’s blog</title><subtitle>Data science + data engineering posts</subtitle><entry><title type="html">Incremental Dbt</title><link href="http://localhost:4000/blog/incremental-dbt/" rel="alternate" type="text/html" title="Incremental Dbt" /><published>2020-12-24T00:00:00-05:00</published><updated>2020-12-24T00:00:00-05:00</updated><id>http://localhost:4000/blog/incremental-dbt</id><content type="html" xml:base="http://localhost:4000/blog/incremental-dbt/">&lt;h1 id=&quot;adventures-in-incremental-dbt&quot;&gt;Adventures in incremental dbt&lt;/h1&gt;
&lt;p&gt;(For those of you who don't know what &lt;code&gt;dbt&lt;/code&gt; is or how it works, parts of this post might be confusing. I'd recommend starting with the documentation and working through an example to get your feet wet. That being said, if you know SQL and a little bit of Jinja, most of what I write below should make sense.)&lt;/p&gt;
&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;I love &lt;code&gt;dbt&lt;/code&gt;. It is a tool for &amp;quot;ELT&amp;quot;, as opposed to &amp;quot;ETL&amp;quot;: in other words, transforming the &amp;quot;source&amp;quot; data in your data lake/data warehouse after it has been loaded, as opposed to before.&lt;/p&gt;
&lt;p&gt;(The reasons you might want to adopt the ELT paradigm are too involved to explain in this post, but one main one is that transforming the source data &lt;em&gt;before&lt;/em&gt; it arrives in your data warehouse is often irreversible and therefore inflexible. By contrast, transforming the raw data &lt;em&gt;after&lt;/em&gt; is reversible: if you decide that a different data model is appropriate, you can simply wipe away the previously generated &amp;quot;transformed data&amp;quot; and start anew from the source data.)&lt;/p&gt;
&lt;p&gt;A &lt;a href=&quot;https://blog.getdbt.com/future-of-the-modern-data-stack/&quot;&gt;few different trends&lt;/a&gt; have driven the rapid adoption of &lt;code&gt;dbt&lt;/code&gt;. First, the relative cheapness of storage means that storing source data in a raw, unaggregated form is economical. Second, the rise of data warehouses such as Redshift and Snowflake means that this SQL &amp;quot;transformation layer&amp;quot; is both easy to write and performant on large datasets. Redshift and Snowflake support distributed/parallel SQL in a way that traditional &amp;quot;OLTP&amp;quot; databases, such as Postgres, do not.&lt;/p&gt;
&lt;p&gt;Typically, &lt;code&gt;dbt&lt;/code&gt; is run as a nightly cron job: each night, it will execute a set of SQL queries against the raw source data and produce the &amp;quot;derived&amp;quot; or &amp;quot;transformed&amp;quot; data, which are the tables that support your analysts, dashboards, and possibly even ML applications. This process might strike you as inefficient, particularly for source data that comprises (stateless) events. If only the source data loaded in the last 24 hours has changed between the prior &lt;code&gt;dbt&lt;/code&gt; run and the current one, why not simply process that data instead of reprocessing the entire table?&lt;/p&gt;
&lt;p&gt;For this purpose, &lt;code&gt;dbt&lt;/code&gt; supplies the concept of &amp;quot;incremental&amp;quot; materialization: instead of reprocessing the entire source table, we can process the &lt;em&gt;increment&lt;/em&gt; of new data. In this post, I will use a case study to demonstrate how this works and some problems I've run into.&lt;/p&gt;
&lt;h2 id=&quot;a-case-study&quot;&gt;A case study&lt;/h2&gt;
&lt;p&gt;Suppose we have a table called &lt;code&gt;user_transactions&lt;/code&gt;. It captures the revenue for each transaction (say, buying an item on our e-commerce store) associated with a user. It might look like this:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;center&quot;&gt;user_id&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;birth_date&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;date&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;revenue&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-01&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-01&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-01&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-01&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-01&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-03&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;6.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-01&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-07&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;14.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-01&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-08&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;5.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;2&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-02&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-05&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;6.00&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Here, the &lt;code&gt;user_id&lt;/code&gt; is the unique identifier for the user; the &lt;code&gt;date&lt;/code&gt; is the date of activity (the date the transaction occurred); the &lt;code&gt;birth_date&lt;/code&gt; is the date the user joined our service (was &amp;quot;born&amp;quot;), and the &lt;code&gt;revenue&lt;/code&gt; is the dollar amount collected. We can, of course, have multiple transactions for a user on a particular date.&lt;/p&gt;
&lt;p&gt;(One subtle point: Note that this representation is denormalized, since the &lt;code&gt;user_id&lt;/code&gt; + &lt;code&gt;birth_date&lt;/code&gt; relationship is fixed, and could/should be a separate table. In other words, we could have a separate &lt;code&gt;users&lt;/code&gt; table, of which the &lt;code&gt;birth_date&lt;/code&gt; is a dimension. The &lt;code&gt;users&lt;/code&gt; table would be a &lt;code&gt;dimension&lt;/code&gt; table, &lt;a href=&quot;https://stackoverflow.com/questions/20036905/difference-between-fact-table-and-dimension-table&quot;&gt;in the language&lt;/a&gt; of data modeling, and the original &lt;code&gt;user_transactions&lt;/code&gt; table would become a fact table. In what follows, however, I've chosen to keep this denormalized representation because it makes writing the subsequent SQL easier.)&lt;/p&gt;
&lt;p&gt;Our goal in this case study is to compute the cumulative revenue per user for various time windows: specifically, 3, 7, 60, and 365 days after the user joined our service. We refer to the cumulative revenue up to day N as the &amp;quot;DN revenue&amp;quot;. For the example data above, user 1's D1 revenue is $20.00; D2 revenue is $30.00, and D4 revenue is $81.00. In contrast, user 3's D1 and D2 revenue is $0.00 (they did not spend in the their first 2 days), but their D4 revenue is $30.00.&lt;/p&gt;
&lt;p&gt;(Another subtle point: some numbering conventions use 0-based indexing, so that our &amp;quot;D1 revenue&amp;quot; would be equivalent to their &amp;quot;D0 revenue&amp;quot;. Be attentive to this &amp;quot;off-by-one&amp;quot; issue when writing your own business logic.)&lt;/p&gt;
&lt;h3 id=&quot;attempt-1-full-table-refresh&quot;&gt;Attempt 1: full table refresh&lt;/h3&gt;
&lt;p&gt;The simplest approach is to create a derived table (say, &lt;code&gt;user_cumulative_revenue&lt;/code&gt;), and to refresh the entire table each day. The SQL would look like this:&lt;/p&gt;
&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;user_id&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;birth_date&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SUM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;CASE&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;WHEN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DATEDIFF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;DAY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;birth_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;THEN&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;revenue&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;ELSE&lt;/span&gt;
            &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;END&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d3_revenue&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SUM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;CASE&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;WHEN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DATEDIFF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;DAY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;birth_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;THEN&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;revenue&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;ELSE&lt;/span&gt;
            &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;END&lt;/span&gt;
     &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d7_revenue&lt;/span&gt;
     &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ref&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'user_transactions'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;(where &lt;code&gt;ref&lt;/code&gt; is &lt;code&gt;dbt&lt;/code&gt;'s way of referring to other tables/data sources. Note that &lt;code&gt;[source](https://docs.getdbt.com/docs/building-a-dbt-project/using-sources/)&lt;/code&gt; might be even better than &lt;code&gt;ref&lt;/code&gt; here.)&lt;/p&gt;
&lt;p&gt;Using &lt;code&gt;dbt&lt;/code&gt;'s jinja functionality, we can clean up the repetitive logic like so:&lt;/p&gt;
&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- attempt_1.sql&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_windows&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;365&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;user_id&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;birth_date&lt;/span&gt;
    &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_window&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_windows&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SUM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;CASE&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;WHEN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DATEDIFF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;DAY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;birth_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_window&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;THEN&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;revenue&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;ELSE&lt;/span&gt;
            &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;END&lt;/span&gt;
     &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_window&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_revenue&lt;/span&gt;
     &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;endfor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ref&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'user_transactions'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;There's still one error in our logic, however. For day windows that are &amp;quot;incomplete&amp;quot; — for instance, if a user has been with us for only 2 days but we want to find their D3 revenue — we should make the result &lt;code&gt;NULL&lt;/code&gt;. We want to calculate the D3 revenue only when the 3 day window for a particular user is complete. We can incorporate that logic like so:&lt;/p&gt;
&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- attempt_1_fixed.sql&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_windows&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;365&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;user_id&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;birth_date&lt;/span&gt;
    &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_window&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_windows&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,(&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;CASE&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;WHEN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DATEDIFF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;DAY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;birth_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CURRENT_DATE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_window&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;THEN&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;SUM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;CASE&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;WHEN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DATEDIFF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;DAY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;birth_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_window&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;THEN&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;revenue&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;ELSE&lt;/span&gt;
                    &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;END&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;ELSE&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;NULL&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;END&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_window&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_revenue&lt;/span&gt;
    &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;endfor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ref&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'user_transactions'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;(Lots of nesting! This could be simplified if your database supports the &lt;code&gt;IFF&lt;/code&gt; and/or &lt;code&gt;NULLIF&lt;/code&gt; keywords.)&lt;/p&gt;
&lt;p&gt;In other words, we set the DN revenue to be &lt;code&gt;NULL&lt;/code&gt; if insufficient time has elapsed between the user's &lt;code&gt;birth_date&lt;/code&gt; and the current date.&lt;/p&gt;
&lt;p&gt;(One more subtle note: I'm assuming that the last &lt;em&gt;complete&lt;/em&gt; day of data is &lt;code&gt;CURRENT_DATE - 1&lt;/code&gt; . This is true if the &lt;code&gt;dbt&lt;/code&gt; job runs somewhat after midnight UTC and our data is loaded in a timely way. In practice, this assumption might be dangerous, however, and data &lt;a href=&quot;https://docs.getdbt.com/reference/commands/source#dbt-source-snapshot-freshness&quot;&gt;&amp;quot;freshness&amp;quot;&lt;/a&gt; checks are probably needed.)&lt;/p&gt;
&lt;h3 id=&quot;attempt-2-incremental-naive&quot;&gt;Attempt 2: incremental, naive&lt;/h3&gt;
&lt;p&gt;The approach developed above &amp;quot;works&amp;quot;, but you might notice that it's rather inefficient. First of all, even though our maximum LTV window is 365 days, our query scans over the  entire &lt;code&gt;user_transactions&lt;/code&gt; table, even for users who joined more than 365 days ago, and for transactions that occurred more than 365 days ago. If we were to filter out these users and transactions, however, then the data for them would not appear in the final table, which is bad. What we need is a way to update the data for the last 365 days without destroying the data from dates before that. &lt;code&gt;dbt&lt;/code&gt;'s default approach is to destroy the previous table and create a new one, which isn't appropriate in this case.&lt;/p&gt;
&lt;p&gt;Enter the &lt;code&gt;dbt&lt;/code&gt; incremental materialization. Here, we have to define a key or set of keys for &amp;quot;upserting&amp;quot; new data. If the keys for the new rows match those for existing rows in the table, the existing rows are overwritten. If the keys do not match, the new rows are inserted. This might seem confusing, but the basic idea, as applied to this case study, is that our transformed data has a unique id: we have one row per user. We only want to update rows for which the user's &lt;code&gt;birth_date&lt;/code&gt; is in the last 365 days; for older users, their data need not be recomputed, since it is fixed and should not change.&lt;/p&gt;
&lt;p&gt;The SQL looks something like this:&lt;/p&gt;
&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- attempt_2.sql&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;materialized&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'incremental'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;unique_key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'user_id'&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;

&lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_windows&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;365&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;user_id&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;birth_date&lt;/span&gt;
    &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_window&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_windows&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,(&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;CASE&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;WHEN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DATEDIFF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;DAY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;birth_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CURRENT_DATE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_window&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;THEN&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;SUM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;CASE&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;WHEN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DATEDIFF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;DAY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;birth_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_window&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;THEN&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;revenue&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;ELSE&lt;/span&gt;
                    &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;END&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;ELSE&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;NULL&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;END&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_window&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_revenue&lt;/span&gt;
    &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;endfor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ref&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'user_transactions'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;is_incremental&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;DATEDIFF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;DAY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;birth_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CURRENT_DATE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_windows&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;max&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;-- superfluous, but might help query optimizer&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DATEDIFF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;DAY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CURRENT_DATE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_windows&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;max&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;endif&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Pretty simple, right? The only things that have changed are the configuration of the &lt;code&gt;dbt&lt;/code&gt; model and the date filters (in the &lt;code&gt;WHERE&lt;/code&gt; clause). We can run this in &lt;code&gt;full-refresh&lt;/code&gt; mode initially, which will create the entire table from scratch by ignoring the &lt;code&gt;is_incremental&lt;/code&gt; WHERE clause; then, on all subsequent runs, we can run this model in incremental mode, which will respect the &lt;code&gt;is_incremental&lt;/code&gt; &lt;code&gt;WHERE&lt;/code&gt; clause and avoid reprocessing data for old users. For more details on how this works, here is the &lt;a href=&quot;https://docs.getdbt.com/docs/building-a-dbt-project/building-models/configuring-incremental-models/&quot;&gt;dbt documentation&lt;/a&gt; for incremental models.&lt;/p&gt;
&lt;p&gt;(As an aside, this incremental query will be more efficient only if the source data is sorted/indexed appropriately. In Redshift, we would need to have a &lt;a href=&quot;https://www.flydata.com/blog/amazon-redshift-distkey-and-sortkey/&quot;&gt;sort/dist key&lt;/a&gt; that involves either the &lt;code&gt;date&lt;/code&gt; and/or the &lt;code&gt;birth_date&lt;/code&gt;. In Snowflake, these keys/indexes are managed for you, and it is likely that this optimization would take place. If we had separated the source data into dimension and fact tables, the choice of keys would be somewhat different.)&lt;/p&gt;
&lt;h3 id=&quot;attempt-3-incremental-more-sophisticated&quot;&gt;Attempt 3: incremental, more sophisticated&lt;/h3&gt;
&lt;p&gt;It turns out that even this incremental model is rather inefficient, in the sense of scanning over rows that don't matter. How inefficient? Well, each day we have only 4 &lt;code&gt;birth_date&lt;/code&gt; &amp;quot;cohorts&amp;quot; that mature. As an example, let's suppose we are processing data on Jan 1, 2020, and the last date of data available is for Dec 31, 2019. There are four important milestones that have been reached:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The cohort with &lt;code&gt;birth_date&lt;/code&gt; Dec 29, 2019 has completed 3 days of activity, so its D3 revenue can be computed.&lt;/li&gt;
&lt;li&gt;The cohort with &lt;code&gt;birth_date&lt;/code&gt; Dec 25, 2019 has completed 7 days of activity, so its D7 revenue can be computed.&lt;/li&gt;
&lt;li&gt;The cohort with &lt;code&gt;birth_date&lt;/code&gt; Nov 2, 2019 has completed 60 days of activity, so its D60 revenue can be computed.&lt;/li&gt;
&lt;li&gt;The cohort with &lt;code&gt;birth_date&lt;/code&gt; Jan 1, 2019 has completed 365 days of activity, so its D365 revenue can be computed.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Importantly, no other cohorts have matured or hit an important milestone! In other words, if we reprocess the last 365 days of &lt;code&gt;birth_date&lt;/code&gt;s, we will be scanning over 365/4 = 91 times as many rows as is necessary. (Whether this means the query will take 91 times as long is a separate question; it is unlikely that the performance degradation would be that severe.)&lt;/p&gt;
&lt;p&gt;You might argue that modern distributed SQL is fast enough that this doesn't matter. This is probably true for many applications. But, depending on our business model and number of users, the &lt;code&gt;transactions&lt;/code&gt; table might have millions or tens of millions of rows per day, and reprocessing 365 days of it might be too inefficient.&lt;/p&gt;
&lt;p&gt;Regardless, even merely as an intellectual exercise I think it is interesting to see whether we can make this logic more performant, working within the strictures of &lt;code&gt;dbt&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Let's try to directly implement this idea related to cohort maturation. On a given date, we will reprocess only the four &lt;code&gt;birth_date&lt;/code&gt; cohorts that have matured. My attempt looks like this:&lt;/p&gt;
&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- attempt_3.sql&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;materialized&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'incremental'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;unique_key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'user_id'&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;

&lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_windows&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;365&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;user_id&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;birth_date&lt;/span&gt;
    &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_window&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_windows&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,(&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;CASE&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;WHEN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DATEDIFF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;DAY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;birth_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CURRENT_DATE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_window&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;THEN&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;SUM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;CASE&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;WHEN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DATEDIFF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;DAY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;birth_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_window&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;THEN&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;revenue&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;ELSE&lt;/span&gt;
                    &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;END&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;ELSE&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;NULL&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;END&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_window&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_revenue&lt;/span&gt;
    &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;endfor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ref&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'user_transactions'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;is_incremental&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;DATEDIFF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;DAY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CURRENT_DATE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_windows&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;max&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_window&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_windows&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;DATEDIFF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;DAY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;birth_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CURRENT_DATE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_window&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;
        &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;last&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt;
        &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;endif&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;endfor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;endif&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;which is starting to get more complicated! We have to modify the &lt;code&gt;WHERE&lt;/code&gt; clause to filter using equality statements, chained with OR, for the &lt;code&gt;birth_date&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&quot;unpivoting&quot;&gt;Unpivoting&lt;/h2&gt;
&lt;p&gt;One source of inflexibility with our current approach, which you might have noticed, is that adding new &amp;quot;day windows&amp;quot; is inefficient: we have to run a full table refresh for any new columns. In other words, if we want to compute a new, D1 cumulative revenue, the incremental materialization doesn't help us.&lt;/p&gt;
&lt;p&gt;One way to surmount this difficulty is to &lt;a href=&quot;https://github.com/fishtown-analytics/dbt-utils#unpivot-source&quot;&gt;&amp;quot;unpivot&amp;quot;&lt;/a&gt; the table: for each user, we will have N rows, one for each day window of interest. Then, when we need to add a new day window, all we need to do is insert a new row for each user, and this operation does not require a full table refresh. This might be a bit tough to visualize, so here is what the old table looked like:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;center&quot;&gt;user_id&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;birth_date&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;d3_revenue&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;d7_revenue&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;d60_revenue&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;d365_revenue&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-01&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;10.00&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;24.00&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;NULL&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;NULL&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;2&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-02&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;0.00&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;6.00&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;NULL&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;NULL&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;and this is what the new, pivoted table looks like:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;center&quot;&gt;user_id&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;birth_date&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;day_window&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;revenue&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-01&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;3&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;10.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-01&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;7&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;24.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;2&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-02&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;3&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;0.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;2&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-02&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;7&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;6.00&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The unique key for upsertion, in this case, is the combination of the &lt;code&gt;user_id&lt;/code&gt; and the &lt;code&gt;day_window&lt;/code&gt;. How might this model be represented in &lt;code&gt;dbt&lt;/code&gt;? It's not too different from our previous model:&lt;/p&gt;
&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- attempt_pivot_incremental.sql&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;materialization&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'incremental'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;unique_key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'user_day_window_id'&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;

&lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_windows&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;365&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;WITH&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;user_id&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;birth_date&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DATEDIFF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;DAY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;birth_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CURRENT_DATE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_window&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SUM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;revenue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cumulative_revenue&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ref&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'user_transactions'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;-- select birth_dates that correspond to cohort maturation on CURRENT_DATE - 1&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_window&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_windows&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;DATEDIFF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;DAY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;birth_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CURRENT_DATE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_window&lt;/span&gt;
        &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;last&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt;
        &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;endif&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;endfor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;-- superfluous, but might help query optimizer&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;date&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;birth_date&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DATEDIFF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;DAY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CURRENT_DATE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;day_windows&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dbt_utils&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;surrogate_key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'user_id'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'day_window'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;user_day_window_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;When we turn to the &amp;quot;full table&amp;quot; model, things get complicated, though. It is not obvious how to implement this model (without using the &lt;code&gt;unpivot&lt;/code&gt; macro), which means that we cannot easily have the incremental and full models in the same model file, which &lt;code&gt;dbt&lt;/code&gt; requires. (If you have ideas, let me know!)&lt;/p&gt;
&lt;p&gt;(My best guess is that the solution involves some complicated SQL/Jinja to generate all possible combinations of (&lt;code&gt;day_window&lt;/code&gt;, &lt;code&gt;birth_date&lt;/code&gt;) tuples, and then joining that to the &lt;code&gt;user_transactions&lt;/code&gt; table. In addition to being complicated, this might also be inefficient.)&lt;/p&gt;
&lt;h2 id=&quot;taking-a-step-back&quot;&gt;Taking a step back&lt;/h2&gt;
&lt;p&gt;Even if there is a solution to this issue, I think the difficulties we had constructing it point to some deficiencies with dbt:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Writing incremental models involves reasoning carefully about the differences between the full and incremental models, and trying to include both sets of logic in a single model. This often requires SQL/Jinja gymnastics, if it is indeed possible at all.&lt;/li&gt;
&lt;li&gt;We often don't even need the full table model. We could, instead, compose the table of interest by iterating over individual incremental runs. &lt;code&gt;dbt&lt;/code&gt; does not easily support this functionality, though. &amp;quot;For&amp;quot; loops must be written within model files; they cannot be used to iterate over &lt;code&gt;dbt&lt;/code&gt; runs.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Let me try to expand upon point 2. One relatively straightforward approach would be to run the dbt model for a single tuple of (&lt;code&gt;day_window&lt;/code&gt;, &lt;code&gt;date_of_interest&lt;/code&gt;). How might this look? (I'm using the &lt;code&gt;[vars&lt;/code&gt; syntax](&lt;a href=&quot;https://docs.getdbt.com/docs/building-a-dbt-project/building-models/using-variables/&quot;&gt;https://docs.getdbt.com/docs/building-a-dbt-project/building-models/using-variables/&lt;/a&gt;) to pass these variables into the model.)&lt;/p&gt;
&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- attempt_single_tuple_incremental.sql&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;materialization&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'incremental'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;unique_key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'user_day_window_id'&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;WITH&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;user_id&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;birth_date&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;&quot;day_window&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day_window&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SUM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;revenue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cumulative_revenue&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ref&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'user_transactions'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;DATEDIFF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;DAY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;birth_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'{{ var(&quot;date_of_interest&quot;) }}'&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;&quot;day_window&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;date&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'{{ var(&quot;date_of_interest&quot;) }}'&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dbt_utils&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;surrogate_key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'user_id'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'day_window'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;user_day_window_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;There's actually hardly any Jinja in this solution at all! On a particular date of interest (which we had taken to be synonymous with the current date, but could really be any date at all), we can get the desired &lt;code&gt;birth_date&lt;/code&gt; cohort by subtracting the &lt;code&gt;day_window&lt;/code&gt; from that date. For instance, for a date of interest of Jan 1, 2020, and a &lt;code&gt;day_window&lt;/code&gt; of 365, the &lt;code&gt;birth_date&lt;/code&gt; is Jan 1, 2019. Then, we simply grab all the transactions that occurred before the date of interest, for users with that birth date. Each &lt;code&gt;dbt&lt;/code&gt; run would be very fast to execute, particularly for short day windows, but there would be a &lt;em&gt;lot&lt;/em&gt; of runs: N_dates * N_day_windows.&lt;/p&gt;
&lt;p&gt;Note further that, in theory, all of these runs could be executed concurrently. Because each of them generates a separate set of rows (since each deals with a distinct &lt;code&gt;user_day_window_id&lt;/code&gt;), none of the runs should, again in theory, interfere with one another. This could make the &amp;quot;backfill&amp;quot; (the initial run to build the table from scratch from historical data) rather fast to execute.&lt;/p&gt;
&lt;p&gt;This approach is very similar to the &amp;quot;functional&amp;quot; approach to transformations, discussed &lt;a href=&quot;https://medium.com/@maximebeauchemin/functional-data-engineering-a-modern-paradigm-for-batch-data-processing-2327ec32c42a&quot;&gt;here&lt;/a&gt;. Each dbt run would process a chunk of data and generate a disjoint &amp;quot;partition&amp;quot;, indexed by the &lt;code&gt;user_day_window_id&lt;/code&gt;. The final table can be thought of as the UNION ALL of each of these different &lt;code&gt;user_day_window&lt;/code&gt; partitions.&lt;/p&gt;
&lt;p&gt;Another benefit of this approach is supporting &amp;quot;late arriving&amp;quot; events: in this case, transactions for which the data is received one or more days late, or cases where a transaction is refunded, so we have an additional, negative transaction that arrives one or more days later. We can incorporate these late arriving events into our logic by also running the dbt job for a previous date of interest (say, 7 days ago, by which time we can assume all of the late arriving events have &amp;quot;settled&amp;quot;). This would ensure that we have approximate results immediately, and correct results with a 7 day lag. Again, the normal job and the late arriving job could conceivably run concurrently.&lt;/p&gt;
&lt;p&gt;In practice, on the other hand, implementing this solution is not at all easy:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Multiple &lt;code&gt;dbt&lt;/code&gt; jobs can be run concurrently, but it is not safe to do so. In particular, the names of intermediate VIEWs might clash, which would lead to race conditions and other bad outcomes.&lt;/li&gt;
&lt;li&gt;Databases like Redshift struggle with concurrent writes because of serializability guarantees. Telling the compiler that the partitions being generated are indeed disjoint is not easy.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dbt&lt;/code&gt; does not natively support looping over runs/tasks and supplying &amp;quot;logical dates&amp;quot; in the way that a workflow management tool like &lt;a href=&quot;https://airflow.apache.org/&quot;&gt;Airflow&lt;/a&gt; does. dbt has to be combined with a tool like Airflow to get this functionality. We need the logical date to support things like backfills, retries, table rebuilds using incremental logic alone, and late arriving events. (We can use Airflow's &lt;code&gt;ds&lt;/code&gt; as dbt's &lt;code&gt;var(&amp;quot;date_of_interest&amp;quot;)&lt;/code&gt;.)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;(Others have encountered related issues: &lt;a href=&quot;https://shopify.engineering/build-production-grade-workflow-sql-modelling&quot;&gt;Shopify mentioned&lt;/a&gt; that &amp;quot;dbt’s current incremental support doesn’t provide safe and consistent methods to handle late arriving data, key resolution, and rebuilds. For this reason, a handful of models (Type 2 dimensions or models in the 1.5B+ event territory) that required incremental semantics weren’t doable—for now.&amp;quot;)&lt;/p&gt;
&lt;p&gt;It would be nice to see &lt;code&gt;dbt&lt;/code&gt; try to support this more functional approach to writing transformations. I imagine it will be difficult given the issues I've mentioned, particularly on the database side, but I'm curious to see what their team of very smart engineers can cook up!&lt;/p&gt;
&lt;p&gt;(The Github code for this project is available &lt;a href=&quot;https://github.com/varunprajan/data-eng-blog/tree/main/incremental-dbt&quot;&gt;here&lt;/a&gt;, if you're interested. The &lt;code&gt;user_transactions&lt;/code&gt; table is generated using &lt;code&gt;dbt seed&lt;/code&gt;.)&lt;/p&gt;</content><author><name></name></author><summary type="html">Adventures in incremental dbt</summary></entry><entry><title type="html">Retry-driven development</title><link href="http://localhost:4000/blog/retry-driven-development/" rel="alternate" type="text/html" title="Retry-driven development" /><published>2020-12-20T23:07:59-05:00</published><updated>2020-12-20T23:07:59-05:00</updated><id>http://localhost:4000/blog/retry-driven-development</id><content type="html" xml:base="http://localhost:4000/blog/retry-driven-development/">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;I usually advise against writing your own ETL jobs. Commercial products such as Stitch and Fivetran integrate with hundreds of data sources and dozens of data destinations; they make ETL maintainable and easy. But, whether for reasons of cost or functionality, you might be forced to write your own ETL. How do you do that in a way that avoids its common pitfalls? (To &lt;a href=&quot;https://medium.com/@maximebeauchemin/functional-data-engineering-a-modern-paradigm-for-batch-data-processing-2327ec32c42a&quot;&gt;quote&lt;/a&gt; Maxime Beauchemin, creator of Apache Superset and Apache Airflow: &amp;quot;Batch data processing — historically known as ETL — is extremely challenging. It’s time-consuming, brittle, and often unrewarding. Not only that, it’s hard to operate, evolve, and troubleshoot.&amp;quot;)&lt;/p&gt;
&lt;p&gt;Data engineers should obviously borrow best practices from other disciplines of software engineering: writing clear documentation, developing robust unit and integration tests, soliciting PR reviews, etc. One under-appreciated method that has special relevance to data/analytics engineering is what I'll call &amp;quot;retry-driven development&amp;quot;. In short, &lt;em&gt;write your code in such a way that it can be retried safely and correctly&lt;/em&gt;. In other words, accept that bugs can happen that will not be covered by your test suite, but be able to recover from them effectively.&lt;/p&gt;
&lt;p&gt;To be clear, I am not claiming credit for this idea. In fact, much of this post is inspired by Beauchemin's excellent &lt;a href=&quot;https://medium.com/@maximebeauchemin/functional-data-engineering-a-modern-paradigm-for-batch-data-processing-2327ec32c42a&quot;&gt;essay&lt;/a&gt; &amp;quot;Functional Data Engineering: A Modern Paradigm for Batch Data Processing&amp;quot; (and he himself acknowledges that mature companies have been employing these ideas for years, perhaps without formalizing them in the way he has). My hope is instead to work through a concrete case study that might help illuminate some of the slightly abstract concepts he discussed.&lt;/p&gt;
&lt;h2 id=&quot;a-case-study&quot;&gt;A case study&lt;/h2&gt;
&lt;p&gt;Suppose we work for a retail company that has historically operated only in the United States, but now seeks to expand its operations worldwide. We can imagine an &lt;code&gt;order_items&lt;/code&gt; table that used to look like this:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;center&quot;&gt;order_item_id&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;order_id&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;item_name&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;amount_usd&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;ordered_at&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;Breezy Dress&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;53.49&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-01 02:00:01&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;2&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;V-neck Shirt&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;18.99&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-03 04:00:01&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;3&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;Muscle Tank&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;42.69&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-03 04:00:01&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;But will be migrated to look like this (note the additional item in a non-USD currency):&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;center&quot;&gt;order_item_id&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;order_id&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;item_name&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;amount&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;currency_code&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;ordered_at&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;Breezy Dress&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;53.49&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;USD&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-01 02:00:01&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;2&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;V-neck Shirt&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;18.99&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;USD&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-03 04:00:01&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;3&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;Muscle Tank&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;42.69&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;USD&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-03 04:00:01&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;4&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;3&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;Red Sari&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;1800.00&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;INR&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-05 23:49:04&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We would like to be able to continue reporting our daily gross revenue (in USD) in our company &amp;quot;key metrics email&amp;quot;. To do this, we will collect data on a daily basis for worldwide exchange rates in terms of USD. Suppose this table is called &lt;code&gt;historical_exchange_rates&lt;/code&gt;, with three columns, &lt;code&gt;date&lt;/code&gt; ,&lt;code&gt;currency_code&lt;/code&gt;, and &lt;code&gt;exchange_rate_usd&lt;/code&gt;, like so:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;center&quot;&gt;date&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;currency_code&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;exchange_rate_usd&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-01&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;USD&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;1.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-01&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;INR&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;0.0136&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;2020-12-02&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;USD&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;1.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;...&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;...&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;...&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;our revenue query for the report would be:&lt;/p&gt;
&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ordered_at&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;DATE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;-- ignore revenue for which a matching code/date cannot be found&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SUM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;amount&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;COALESCE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exchange_rate_usd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;order_items&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LEFT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;historical_exchange_rates&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rates&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ordered_at&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;DATE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;date&lt;/span&gt;
                                             &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;currency_code&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;currency_code&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;-- only report on data from the last 60 days&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ordered_at&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CURRENT_DATE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;INTERVAL&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'60 DAY'&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;which is actually fairly straightforward. (Whether this is good enough for financial reporting is a separate issue that is out of scope for this post.)&lt;/p&gt;
&lt;h2 id=&quot;etl-first-attempt&quot;&gt;ETL, first attempt&lt;/h2&gt;
&lt;p&gt;Our first attempt at an ETL script for this &lt;code&gt;historical_exchange_rates&lt;/code&gt; table might look something like the Python code below. For brevity, I've omitted many of the details, but the entire script is available on Github [TODO]).&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;logging&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;logger&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logging&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getLogger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__name__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;BASE_CURRENCY&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;USD&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;DB_CONN&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RedshiftConnection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(...)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;EMAIL_RECIPIENTS&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;alex@retailstartup.com&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;varun@retailstartup.com&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;EXCHANGE_RATES_URL&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;https://openexchangerates.org/api/&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;TABLE_NAME&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;historical_exchange_rates&quot;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;retrieve_exchange_rates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base_currency&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;transform_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;raw_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;append_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db_conn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'DatabaseConnection'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# retrieve raw data for today by making a request to the API
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;json_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;retrieve_exchange_rates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;base_currency&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BASE_CURRENCY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EXCHANGE_RATES_URL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# transform data into pandas dataframe
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;frame&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transform_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;raw_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;json_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# insert (append) it into our data warehouse table
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;append_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db_conn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DB_CONN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;table&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TABLE_NAME&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# email recipients that job finished
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;email_notification&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;recipients&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EMAIL_RECIPIENTS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;contents&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Exchange rate job succeeded!&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__name__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;__main__&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;except&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Exception&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;logger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;info&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;f&quot;Something bad happened, exception info: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;email_notification&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;recipients&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EMAIL_RECIPIENTS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;contents&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Exchange rate job failed; check logs&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;There are a lot of things to like here (at least I hope so; I'm the one who wrote it!). The code seems fairly modular, and it has function names that make sense. It also uses type hints, which can be enforced &lt;a href=&quot;http://mypy-lang.org/&quot;&gt;using &lt;code&gt;mypy&lt;/code&gt;&lt;/a&gt;. Suppose further that it has a test suite with full coverage that mocks out the API and database; the tests run via Jenkins; the code is deployed with a one-button deployment; and the job itself runs on a cron at UTC midnight but can be retried with a one-button click if needed. I would wager that this code quality and deployment process is better than many custom-built ETL pipelines at small/medium-sized companies.&lt;/p&gt;
&lt;p&gt;Yet it is also the case that this ETL pipeline does not work well. The issues stem from violating the principle of retry-driven development: if something fails, the code cannot be retried safely and/or correctly. There are a few reasons:&lt;/p&gt;
&lt;h2 id=&quot;lack-of-separation-of-environments&quot;&gt;Lack of separation of environments&lt;/h2&gt;
&lt;p&gt;Suppose something in the ETL job breaks (as it inevitably will). We would like to tinker with and run the code locally in order to debug the issue. Is this safe to do? Actually, no. Unless we have a way to mock out the (Redshift) data warehouse locally, we risk writing to our production table. And, if the Redshift connection were mocked locally, we would not be able to test that the &lt;code&gt;append_data&lt;/code&gt; function works properly. (Note that, since our test suite uses mocks, it also does not truly test the functionality of this method). What we need is a way to run a job locally that does not touch production data, but still touches Redshift.&lt;/p&gt;
&lt;p&gt;One easy way to support this workflow is to create a development schema (let's say, &lt;code&gt;varun_dev&lt;/code&gt;). (As an aside, &lt;code&gt;dbt&lt;/code&gt; enforces &lt;a href=&quot;https://docs.getdbt.com/docs/building-a-dbt-project/building-models/using-custom-schemas#managing-environments&quot;&gt;this same workflow&lt;/a&gt;). Then, we can use a Python package (I prefer &lt;a href=&quot;https://www.dynaconf.com/&quot;&gt;&lt;code&gt;dynaconf&lt;/code&gt;&lt;/a&gt;, but there are others) that sets a configuration variable differently if the code is run in the &amp;quot;development&amp;quot; environment vs. the &amp;quot;production&amp;quot; one. The code would look something like this:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;dynaconf&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;settings&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# this will be, say, &quot;raw&quot; in production but &quot;varun_dev&quot; in development
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SCHEMA_NAME&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;settings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;HISTORICAL_EXCHANGE_RATES&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SCHEMA_NAME&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# insert (append) it into our data warehouse table
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;append_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db_conn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DB_CONN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;table&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TABLE_NAME&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;schema&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SCHEMA_NAME&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;A further advantage of this approach is that multiple developers can work on the same code without interfering with each other: each will have their own development schema.&lt;/p&gt;
&lt;h2 id=&quot;issues-with-append&quot;&gt;Issues with append&lt;/h2&gt;
&lt;p&gt;Another problem with the current code has to do with the &amp;quot;append_data&amp;quot; function. Suppose the implementation uses Redshift's &lt;code&gt;COPY&lt;/code&gt; &lt;a href=&quot;https://docs.aws.amazon.com/redshift/latest/dg/r_COPY.html&quot;&gt;command&lt;/a&gt;: we write our &lt;code&gt;pandas&lt;/code&gt; dataframe to a temporary csv on S3, and then use &lt;code&gt;COPY&lt;/code&gt; to load the data from that csv into our table, by appending it to the existing data.&lt;/p&gt;
&lt;p&gt;If we retry our code, there is an issue: we don't know whether this will correct the previous failure, or if it will instead append the data &lt;em&gt;yet again&lt;/em&gt; to the table. In other words, we could have two copies of the data for a particular day, or just one.&lt;/p&gt;
&lt;p&gt;If, say, Alex leaves the company (☹️), and his email address is disabled, then our &lt;code&gt;email_notification&lt;/code&gt; function might error out, but the data in Redshift will have been loaded correctly. If, on the other hand, the failure occurs because the API was down, then the data in Redshift has not already been loaded. This behavior means we cannot safely retry the ETL job.&lt;/p&gt;
&lt;p&gt;At this point, you might ask: why can't we simply check whether the data was loaded? If it was, we don't have to retry the script; if it wasn't, we can retry the script. I would argue very strongly against this idea. Each of these manual checks adds a &amp;quot;tax&amp;quot; to the process of maintaining an ETL job. Perhaps this tax is bearable with a small number of ETL pipelines, but, as the data volume grows and the ETL complexity grows correspondingly, it will erode an analytics engineer's productive time. It would be nice if, having fixed the issue at 2 am, in advance of the morning's company metrics email, I could simply push the button to run the script and go to bed. If we feel that &amp;quot;one button&amp;quot; development processes, like CI and CD, are valuable, then &amp;quot;one button&amp;quot; ETL runs are valuable for the same reason.&lt;/p&gt;
&lt;p&gt;There are at least two ways to fix the issue with &amp;quot;append&amp;quot; I diagnosed above. One is to avoid using append; the other is to modularize our tasks in the same way that we modularized our code. Let's go one-by-one.&lt;/p&gt;
&lt;h3 id=&quot;upsert-dont-append&quot;&gt;Upsert, don't append&lt;/h3&gt;
&lt;p&gt;Upsertion is a process of updating a table wherein rows that &amp;quot;match&amp;quot; are UPdated, whereas rows that don't &amp;quot;match&amp;quot; are inSERTed (hence the name, &amp;quot;UPSERTion&amp;quot;). What does &amp;quot;match&amp;quot; mean in this context? We typically define a set of &amp;quot;primary keys&amp;quot; — the combination of these primary keys defines a unique id for the row/record. If we attempt to upsert a new row where the set of primary keys match another row already in the table, then that old row is replaced with the new one. If there is no match, a new row is inserted.&lt;/p&gt;
&lt;p&gt;(As an aside, the &lt;a href=&quot;https://docs.getdbt.com/docs/building-a-dbt-project/building-models/configuring-incremental-models/#how-do-incremental-models-work-behind-the-scenes&quot;&gt;details&lt;/a&gt; of how this is implemented vary from database to database. One simple strategy is to delete records for which the keys match, and then insert the entire dataset afterwards. Some databases, like Snowflake, support upsertion &lt;a href=&quot;https://docs.snowflake.com/en/sql-reference/sql/merge.html&quot;&gt;more natively&lt;/a&gt; though.)&lt;/p&gt;
&lt;p&gt;How can we use upsertion to our advantage in this case? By inspecting our &lt;code&gt;historical_exchange_rates&lt;/code&gt; table, we see that the combination of &lt;code&gt;date&lt;/code&gt; and &lt;code&gt;currency_code&lt;/code&gt; define a unique id. Each day we should have exactly one row per currency code. Let's take these two columns to be our primary keys. Suppose we retry the job on the same day. (The &amp;quot;on the same day&amp;quot; is an important caveat, and relaxing this restriction will be covered below.) Then, there are two possibilities:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Our previous job failed before the Redshift load step, in which case no data with &lt;code&gt;date = CURRENT_DATE&lt;/code&gt; exist, so the upsertion process will find no matches. Therefore, the entire dataset resulting from the retry job will be inserted. In this case, that's what we want.&lt;/li&gt;
&lt;li&gt;Our previous job failed after the Redshift load step, in which case data already exists with &lt;code&gt;date = CURRENT_DATE&lt;/code&gt;. The upsertion process will find matches for all of those rows and replace each of them. Arguably this is wasteful (we're replacing old data with identical new data), but it is both safe and correct.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Therefore, replacing our &amp;quot;append&amp;quot; operation with an &amp;quot;upsert&amp;quot; one makes our job safe to retry, with the caveat mentioned before.&lt;/p&gt;
&lt;p&gt;Note that upsertion is a more expensive process than appending: it involves deletes as well as inserts. It can &lt;a href=&quot;https://dataintensive.net/&quot;&gt;also&lt;/a&gt; violate certain database &amp;quot;serializability&amp;quot; guarantees if run concurrently with other processes that hit the same table. Therefore, it may not be appropriate for all cases. Furthermore, for (stateless) events, even the choice of primary keys is not obvious. Pipelines for event-based data typically have to be built with much more care to avoid dropping or duplicating events: i.e., to ensure &amp;quot;exactly once&amp;quot; delivery.&lt;/p&gt;
&lt;h3 id=&quot;modularize-the-tasks&quot;&gt;Modularize the tasks&lt;/h3&gt;
&lt;p&gt;A different approach is to &amp;quot;modularize&amp;quot; our tasks, not just our code. What does this mean? We generally write our code to maximize reusability and obey the single responsibility principle: that each function should do only one thing. Here, one function extracts the data (&lt;code&gt;retrieve_exchange_rates&lt;/code&gt;), another transforms it (&lt;code&gt;transform_data&lt;/code&gt;), another loads it into the data warehouse (&lt;code&gt;append_data&lt;/code&gt; or &lt;code&gt;upsert_data&lt;/code&gt;), and yet another sends the email (&lt;code&gt;email_notification&lt;/code&gt;). However, we have not written our tasks the same way. There is a single script that is executed via cron: it does all of the things listed above in sequence. Because different behavior occurs depending on exactly where this task fails, the retry logic becomes confusing.&lt;/p&gt;
&lt;p&gt;As an alternative, we can break up this single task into two or more tasks. For example:&lt;/p&gt;
&lt;p&gt;Task 1: &lt;code&gt;retrieve_exchange_rates&lt;/code&gt; → &lt;code&gt;transform_data&lt;/code&gt; → &lt;code&gt;upsert_data&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Task 2: &lt;code&gt;email_notification&lt;/code&gt; (depending on status of task 1)&lt;/p&gt;
&lt;p&gt;Why is this better? If task 1 completes successfully, and the data is loaded into the data warehouse, there is no need to retry it. We can instead just fix the email bug and (optionally) retry that task. On the other hand, if task 1 does not complete successfully, we can retry the whole thing (task 1 + task 2) from the beginning.&lt;/p&gt;
&lt;p&gt;You might notice that this is significantly more complicated than a simple cron job. We would like to chain together tasks in some order, store (statefully) the results of the tasks, and retry either from the beginning or partway through. What we are really after is a &amp;quot;workflow management&amp;quot; tool, of which &lt;a href=&quot;https://airflow.apache.org/&quot;&gt;Apache Airflow&lt;/a&gt; is the best-known. The core concept of such a tool is the &amp;quot;DAG&amp;quot;: a graph that describes the tasks and the dependencies between them. (In this case, task 2 depends on task 1, but not the other way around.) If you are interested in learning more, this is the &lt;a href=&quot;https://medium.com/airbnb-engineering/airflow-a-workflow-management-platform-46318b977fd8&quot;&gt;original post&lt;/a&gt; (by the same Maxime Beauchemin!) that announced the open-sourcing of Airflow and shared its design principles.&lt;/p&gt;
&lt;p&gt;You might also ask: why don't we modularize the tasks even further? If our ETL job does four separate things, why don't we have four separate tasks? This is possible and even desirable, but tricky. Remember that, according to our principle, each task needs to be able to be retried safely and correctly. How would we retry the &lt;code&gt;transform_data&lt;/code&gt; task unless we saved the results of the extraction task (&lt;code&gt;retrieve_exchange_rates&lt;/code&gt;) somewhere? Airflow does not natively support this behavior. There are two possibilities. One is to use a tool like &lt;a href=&quot;https://medium.com/the-prefect-blog/why-not-airflow-4cfa423299c4&quot;&gt;Prefect&lt;/a&gt;, which tries to improve upon Airflow by, among other things, supporting the passing of data between tasks (N.B.: I have not used Prefect). The other is to implement data passing using (cloud) storage, such as S3. In other words, we would have tasks like this:&lt;/p&gt;
&lt;p&gt;Task 1: retrieve exchange rates from API, write raw data to S3&lt;/p&gt;
&lt;p&gt;Task 2: read raw data from S3, transform, write transformed data to S3&lt;/p&gt;
&lt;p&gt;Task 3: load transformed data into db from S3&lt;/p&gt;
&lt;p&gt;Task 4: email notification&lt;/p&gt;
&lt;p&gt;Although this makes the code significantly more complicated, using S3 as an intermediate data store is actually a powerful paradigm that has non-obvious advantages, as we will see shortly.&lt;/p&gt;
&lt;p&gt;One final note on this topic: in production, I would recommend using both approaches: task modularization and upserting instead of appending. They do not interfere with one another and might even be seen as complementary.&lt;/p&gt;
&lt;h2 id=&quot;dealing-with-time&quot;&gt;Dealing with time&lt;/h2&gt;
&lt;p&gt;The final problem with our script is that it does not deal with time properly. I hope to clarify this (pseudo-profound) statement with some examples.&lt;/p&gt;
&lt;p&gt;Suppose that we are not able to retry the script on the same day. What happens, even accounting for the improvements made previously (environment separation, upserting instead of appending, and modularizing our tasks)? Unfortunately, we're screwed. If we retry the script on a different day, then it will collect data for that day and populate the &lt;code&gt;historical_exchange_rates&lt;/code&gt; table with it. But this does not solve the problem of the missing data from the day of interest. In other words, the retry is safe, but not correct.&lt;/p&gt;
&lt;p&gt;(Careful readers might notice that even retrying the script on the same day can lead to subtle issues. If the data underlying the exchange rate API changes every hour, then retrying the script in the morning will not produce exactly the same exchange rate data as if it had run successfully at midnight UTC.)&lt;/p&gt;
&lt;p&gt;We can make a final set of improvements to our script. The obvious one is to use the &lt;em&gt;historical&lt;/em&gt; exchange rates API endpoint instead of the current one. This seems easy but in fact it is incompatible with the original cron scheduler. The issue has to do with the &amp;quot;logical date&amp;quot; vs the actual date. If we retry the Dec 1 job on Dec 3, we want the date passed to the API endpoint to be Dec 1, &lt;em&gt;not&lt;/em&gt; Dec 3. In other words, each daily run of the ETL job has a &amp;quot;logical date&amp;quot; associated with it, and, even when retrying later, that logical date needs to be attached to that run. Using the actual date in place of the logical date leads to errors. While cron does not handle this issue, both Airflow and Prefect do.&lt;/p&gt;
&lt;p&gt;For many data sources, historical data is not readily available. The example of exchange rates that forms the basis of the case study might therefore be considered too optimistic. Supporting historical data lookups adds extra work (and possibly also blows up the size of the database backing the API), and many APIs choose not to support it (or, at the very least, limit the amount of time that you can look back). How do we deal with time in these cases?&lt;/p&gt;
&lt;p&gt;The solution is actually one we've already mentioned: modularizing the tasks! The key idea here is that, if we save the raw data first, then &amp;quot;downstream&amp;quot; tasks (tasks that occur after saving the raw data) can be retried both safely and correctly. Of course, if that first task fails, we're still borked, but at least errors in other parts of the code are not critical.&lt;/p&gt;
&lt;p&gt;A final concept related to &amp;quot;dealing with time&amp;quot; is &amp;quot;schema evolution&amp;quot;. It often happens that ETL jobs expand in scope. Our original exchange rate ETL job captured exchange rates in the base currency of USD. Suppose we want to be able to capture other base currencies as well. We can imagine evolving the schema by renaming the &lt;code&gt;exchange_rate_usd&lt;/code&gt; column to &lt;code&gt;exchange_rate&lt;/code&gt;, and adding a &lt;code&gt;base_currency_code&lt;/code&gt; column, backfilled to be &amp;quot;USD&amp;quot; for all existing data.&lt;/p&gt;
&lt;p&gt;While the migration of the table is straightforward, the changes for the ETL job might not be. One final application of the retry-driven development principle is that we want &lt;em&gt;historical&lt;/em&gt; retries, even of successful tasks, to be safe and correct. This gives us some peace of mind: even if the &lt;code&gt;historical_exchange_rates&lt;/code&gt; table gets dropped, for whatever reason, we can rebuild it. This requires writing the &amp;quot;transform&amp;quot; task in a careful way. We could have something like:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;transform_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;raw_data_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_raw_data_from_s3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;original&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transformation&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;code&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;exchange_rate&quot;&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;frame&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;exchange_rate&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;exchange_rate_usd&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;base_currency_code&quot;&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;base_currency_code&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;USD&quot;&lt;/span&gt;

    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;write_transformed_data_to_s3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;As you can see, this code handles the historical and current datasets properly, albeit at the cost of added complexity and extra test cases. If we did not modify it, historical retries could not be run safely or correctly. (There are better ways to handle schema evolution, and products like AWS Glue and Databricks that make this process much easier, but this code snippet was provided simply for the purpose of illustration.)&lt;/p&gt;
&lt;h2 id=&quot;summary-and-conclusions&quot;&gt;Summary and conclusions&lt;/h2&gt;
&lt;p&gt;What I like about this case study is that it is (deceptively) simple, yet it reveals many core concepts to data engineering and even data science. In my view, the principal conclusions are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Be compassionate towards your future self. Your ETL code will undoubtedly break. Write your code so that it can be retried afterwards (i.e., after fixing it) both safely and correctly.&lt;/li&gt;
&lt;li&gt;Retry-driven development has secondary benefits. An important one is that it forces you to break larger tasks down into smaller ones, in the same way that test-driven development forces you to write smaller, more testable functions. The result is &amp;quot;data flows&amp;quot; that are easier to reason about, not only because they are smaller but also because they can be safely retried without much thought.&lt;/li&gt;
&lt;li&gt;Use environments to avoid touching production data. This is probably obvious to those with an engineering background, but perhaps not to some data scientists or &amp;quot;hackers&amp;quot; who are &lt;a href=&quot;https://multithreaded.stitchfix.com/blog/2016/03/16/engineers-shouldnt-write-etl/&quot;&gt;often recruited&lt;/a&gt; to write ETL.&lt;/li&gt;
&lt;li&gt;External data is often ephemeral. If it is not too costly, saving the raw data to a data store is a good way to be able to reconstruct the data of interest at a later date.&lt;/li&gt;
&lt;li&gt;Thinking about time is surprisingly tricky! Try to walk through the possible retry scenarios (rerunning historical tasks, retrying failed tasks on the same day, and on a different day, etc.) before you write code, not after. Distinguishing between the logical data and actual date will help you reason about these cases.&lt;/li&gt;
&lt;li&gt;At some point, cron won't be good enough. Proper workflow management tools add immeasurable value by making recovering from failure straightforward and efficient (only failed tasks need to be retried, not the entire job).&lt;/li&gt;
&lt;li&gt;Upsertion is powerful way to write safe and correct data flows. It ensures that you never duplicate data, which is possible with append-based flows. Much more could be said about this topic, but I'd recommend reading the post by Maxime Beauchemin linked at the top to learn more about &amp;quot;functional data engineering&amp;quot; and &amp;quot;idemptotent&amp;quot; processes (of which upsertion is one).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Let me know your thoughts! Both the first draft and final draft of the ETL script are available on GitHub [TODO], although the Airflow code/DAG is omitted.&lt;/p&gt;</content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html">Introduction</summary></entry></feed>